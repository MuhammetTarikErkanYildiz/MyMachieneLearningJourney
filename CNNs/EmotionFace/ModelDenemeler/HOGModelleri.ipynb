{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HOGModelleri.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Fonksyonlar"
      ],
      "metadata": {
        "id": "i9qi4YDQ6kq-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI5bTns96Xwv"
      },
      "outputs": [],
      "source": [
        "def load_and_prep_image(filename, img_shape=64, colour_channel=\"grayscale\"):\n",
        "  #Read image\n",
        "  img = tf.io.read_file(filename)\n",
        "  #Decode the read file\n",
        "  img= tf.image.decode_image(img)\n",
        "  #Resize the image\n",
        "  img= tf.image.resize(img,size=[img_shape,img_shape])\n",
        "  #Scaling the image\n",
        "  img=tf.image.rgb_to_grayscale(img, name=None)\n",
        "  img= img/255.\n",
        "  return img\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \n",
        "  #import the target image and pre process it\n",
        "  img= load_and_prep_image(filename)\n",
        "\n",
        "  #make predictions\n",
        "  pred = model.predict(tf.expand_dims(img,axis=0))\n",
        "\n",
        "  #Get the predicted class\n",
        "  pred_class= class_names[int(tf.round(pred.argmax()))]\n",
        "  #plot the image and predicted class\n",
        " ##### ? plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.imshow(img)\n",
        "  plt.axis(\"off\")\n",
        "  print(pred_class, pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(history):\n",
        "  \n",
        "  loss= history.history[\"loss\"]\n",
        "  val_loss=history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "  epo= range(len(history.history[\"loss\"]))\n",
        "  \n",
        "\n",
        "  plt.plot(epo, loss, label=\"Training_Loss\")\n",
        "  plt.plot(epo, val_loss, label=\"val_Loss\")\n",
        "  plt.title=(\"Loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(epo, accuracy, label=\"Training_accuracy\")\n",
        "  plt.plot(epo, val_accuracy, label=\"val_accuracy\")\n",
        "  plt.title=(\"accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "jRl2NeK36nnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# İmage Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "    #Setup Target Directory\n",
        "    target_folder= target_dir+\"/\"+target_class\n",
        "    \n",
        "    #Get Random İmage\n",
        "    random_image= random.sample(os.listdir(target_folder),1)\n",
        "    print(random_image)\n",
        "    #Read in the image and plot it using matplotlib\n",
        "    img = mpimg.imread(target_folder+\"/\"+random_image[0])\n",
        "    plt.imshow(img)\n",
        "    plt.title(target_class)\n",
        "    plt.axis(\"off\");\n",
        "    \n",
        "    print(f\"Image shape: {img.shape}\")\n",
        "    \n",
        "    return img"
      ],
      "metadata": {
        "id": "sAamMufF6vdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#THE CONFUSION MATRIX\n",
        "#-------------------------------------------------\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def PrettyConfusionMatrix(y_true,y_pred,classes=None,figsize=(10,10),text_size=15 ):\n",
        "\n",
        "    cm=confusion_matrix(y_true,y_pred)\n",
        "    cm_norm=cm.astype(\"float\")/cm.sum(axis=1)[:,np.newaxis]\n",
        "    n_classes=cm.shape[0]\n",
        "\n",
        "    #Making prettify\n",
        "    fig, ax= plt.subplots(figsize=figsize)\n",
        "    # Create matrix Plot\n",
        "    cax=ax.matshow(cm,cmap=plt.cm.Blues)\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    #Create clases\n",
        "\n",
        "    if classes:\n",
        "        labels=classes\n",
        "    else:\n",
        "        labels=np.arange(cm.shape[0])\n",
        "\n",
        "    #axis labeling\n",
        "    ax.set(title=\"Confusion Matrix\",\n",
        "          xlabel=\"Predicted Label\",\n",
        "          ylabel=\"True Label\",\n",
        "          xticks=np.arange(n_classes),\n",
        "          yticks=np.arange(n_classes),\n",
        "          xticklabels=labels,\n",
        "          yticklabels=labels)\n",
        "    #Set x axis to bottom\n",
        "    ax.xaxis.set_label_position(\"bottom\")\n",
        "    ax.xaxis.tick_bottom()\n",
        "\n",
        "    #Adjust  label size\n",
        "    ax.yaxis.label.set_size(text_size)\n",
        "    ax.xaxis.label.set_size(text_size)\n",
        "    ax.title.set_size(text_size+10)\n",
        "    #set thresh hold for different Colours\n",
        "    threshold= (cm.max()+cm.min())/2\n",
        "\n",
        "    #Plot the text on each cell\n",
        "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "        plt.text(j,i,f\"{cm[i,j]} ({cm_norm[i,j]*100:.1f}%)\",\n",
        "                horizontalalignment= \"center\",\n",
        "                color=\"white\"  if cm[i,j]>threshold else \"black\",\n",
        "                size=15)"
      ],
      "metadata": {
        "id": "NxKh7WR46yN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Datas"
      ],
      "metadata": {
        "id": "Yr3c0tNL6kFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref= zipfile.ZipFile(\"HOG_Datas_Upload.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "My4TmBXm60lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "#walkthrough all classes\n",
        "for dirpath,dirnames , filenames in os.walk(\"HOG_Datas_Upload\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMtq5L-C7ZN0",
        "outputId": "fe413605-14e6-42f6-fbbd-a0e4417af08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in 'HOG_Datas_Upload'.\n",
            "There are 7 directories and 0 images in 'HOG_Datas_Upload/test'.\n",
            "There are 0 directories and 20 images in 'HOG_Datas_Upload/test/angry'.\n",
            "There are 0 directories and 20 images in 'HOG_Datas_Upload/test/happy'.\n",
            "There are 0 directories and 20 images in 'HOG_Datas_Upload/test/sad'.\n",
            "There are 0 directories and 20 images in 'HOG_Datas_Upload/test/disgust'.\n",
            "There are 0 directories and 20 images in 'HOG_Datas_Upload/test/fear'.\n",
            "There are 0 directories and 20 images in 'HOG_Datas_Upload/test/neutral'.\n",
            "There are 0 directories and 20 images in 'HOG_Datas_Upload/test/surprised'.\n",
            "There are 7 directories and 0 images in 'HOG_Datas_Upload/train'.\n",
            "There are 0 directories and 102 images in 'HOG_Datas_Upload/train/angry'.\n",
            "There are 0 directories and 102 images in 'HOG_Datas_Upload/train/happy'.\n",
            "There are 0 directories and 103 images in 'HOG_Datas_Upload/train/sad'.\n",
            "There are 0 directories and 100 images in 'HOG_Datas_Upload/train/disgust'.\n",
            "There are 0 directories and 103 images in 'HOG_Datas_Upload/train/fear'.\n",
            "There are 0 directories and 102 images in 'HOG_Datas_Upload/train/neutral'.\n",
            "There are 0 directories and 101 images in 'HOG_Datas_Upload/train/surprised'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup train and test directories\n",
        "train_dir=\"HOG_Datas_Upload/train/\"\n",
        "test_dir=\"HOG_Datas_Upload/test/\"\n",
        "#Lets get the class names\n",
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "data_dir= pathlib.Path(train_dir)\n",
        "class_names= np.array(sorted(item.name for item in data_dir.glob(\"*\")))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFqVfHb67b00",
        "outputId": "4a851328-e4d8-4622-a93e-afda419a4582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprised']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "IMG_size= 64\n",
        "#Rescale\n",
        "train_datagen= ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen= ImageDataGenerator(rescale= 1/255.)\n",
        "\n",
        "#load data from directories\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                                 target_size=(IMG_size,IMG_size),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                               color_mode= \"grayscale\",\n",
        "                                               shuffle=True)\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                                 target_size=(IMG_size,IMG_size),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                             color_mode= \"grayscale\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-3TAYct7gCU",
        "outputId": "ffa97f66-5c0e-4b55-ab99-7dcc813ac241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 713 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense,Flatten, Conv2D, MaxPool2D,BatchNormalization, Activation\n",
        "from tensorflow.keras import Sequential"
      ],
      "metadata": {
        "id": "Wz_UYZH68NlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_17= Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    BatchNormalization(name='batchnorm_1'),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(16,3, activation=\"relu\"),\n",
        "    Conv2D(16,5, activation=\"relu\"),\n",
        "    BatchNormalization(name='batchnorm_2'),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(40, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_17.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_17=model_17.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "COusUcnQ8EJj",
        "outputId": "b3342efe-23e5-440e-cbd7-3192f4b534b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 18s 286ms/step - loss: 2.2414 - accuracy: 0.2889 - val_loss: 1.9459 - val_accuracy: 0.1429\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 5s 213ms/step - loss: 1.4021 - accuracy: 0.4614 - val_loss: 1.9426 - val_accuracy: 0.1500\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 5s 213ms/step - loss: 1.0050 - accuracy: 0.6185 - val_loss: 1.9438 - val_accuracy: 0.2429\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 5s 213ms/step - loss: 0.7734 - accuracy: 0.7251 - val_loss: 1.9444 - val_accuracy: 0.1429\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 5s 213ms/step - loss: 0.5714 - accuracy: 0.7966 - val_loss: 1.9466 - val_accuracy: 0.1429\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 5s 219ms/step - loss: 0.4460 - accuracy: 0.8415 - val_loss: 1.9589 - val_accuracy: 0.1429\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 5s 213ms/step - loss: 0.3212 - accuracy: 0.8934 - val_loss: 1.9760 - val_accuracy: 0.1429\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 5s 216ms/step - loss: 0.3522 - accuracy: 0.8766 - val_loss: 2.0790 - val_accuracy: 0.1429\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 5s 215ms/step - loss: 0.1947 - accuracy: 0.9425 - val_loss: 2.2282 - val_accuracy: 0.1429\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 5s 216ms/step - loss: 0.1353 - accuracy: 0.9621 - val_loss: 2.2145 - val_accuracy: 0.1429\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 5s 216ms/step - loss: 0.0666 - accuracy: 0.9860 - val_loss: 2.5399 - val_accuracy: 0.1429\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 5s 230ms/step - loss: 0.0519 - accuracy: 0.9930 - val_loss: 2.7194 - val_accuracy: 0.1429\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 5s 233ms/step - loss: 0.0261 - accuracy: 0.9972 - val_loss: 3.3090 - val_accuracy: 0.1429\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 5s 225ms/step - loss: 0.0159 - accuracy: 0.9972 - val_loss: 3.5324 - val_accuracy: 0.1429\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 5s 236ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.6533 - val_accuracy: 0.1429\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d42112d59bc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1203\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1= Sequential([\n",
        "    Conv2D(filters=16, kernel_size=(3,3), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    BatchNormalization(name='batchnorm_1'),\n",
        "    Conv2D(16,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(16,3, activation=\"relu\"),\n",
        "    Conv2D(16,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_1.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_1=model_1.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4zPAu8Zd-Ggz",
        "outputId": "f0b9b1f5-9082-465a-c70f-35012a725c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 8s 227ms/step - loss: 1.8309 - accuracy: 0.2805 - val_loss: 1.9455 - val_accuracy: 0.1429\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 1.1078 - accuracy: 0.6017 - val_loss: 1.9409 - val_accuracy: 0.1643\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 0.5701 - accuracy: 0.8022 - val_loss: 1.9145 - val_accuracy: 0.2929\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 0.2565 - accuracy: 0.8990 - val_loss: 1.8585 - val_accuracy: 0.3714\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 0.1728 - accuracy: 0.9355 - val_loss: 1.8668 - val_accuracy: 0.4000\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 0.0498 - accuracy: 0.9874 - val_loss: 1.7488 - val_accuracy: 0.5143\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 1.7659 - val_accuracy: 0.4929\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 3s 126ms/step - loss: 0.0361 - accuracy: 0.9902 - val_loss: 1.7236 - val_accuracy: 0.6643\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5835 - val_accuracy: 0.6643\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 6.5122e-04 - accuracy: 1.0000 - val_loss: 1.4326 - val_accuracy: 0.7071\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 3s 130ms/step - loss: 0.0322 - accuracy: 0.9972 - val_loss: 1.4428 - val_accuracy: 0.6929\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 3s 130ms/step - loss: 0.0097 - accuracy: 0.9986 - val_loss: 1.3851 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 3s 126ms/step - loss: 0.0382 - accuracy: 0.9944 - val_loss: 1.2096 - val_accuracy: 0.7286\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 0.0146 - accuracy: 0.9972 - val_loss: 1.3292 - val_accuracy: 0.6714\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.7214\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 3s 126ms/step - loss: 2.9679e-04 - accuracy: 1.0000 - val_loss: 0.9352 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 3s 129ms/step - loss: 8.7448e-05 - accuracy: 1.0000 - val_loss: 0.8758 - val_accuracy: 0.7071\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 3s 129ms/step - loss: 6.4868e-05 - accuracy: 1.0000 - val_loss: 0.8400 - val_accuracy: 0.7214\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 5.2063e-05 - accuracy: 1.0000 - val_loss: 0.8254 - val_accuracy: 0.7214\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 3s 131ms/step - loss: 4.5876e-05 - accuracy: 1.0000 - val_loss: 0.8293 - val_accuracy: 0.7286\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 3s 129ms/step - loss: 3.9182e-05 - accuracy: 1.0000 - val_loss: 0.8603 - val_accuracy: 0.7357\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 3.4772e-05 - accuracy: 1.0000 - val_loss: 0.8953 - val_accuracy: 0.7357\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 3.1286e-05 - accuracy: 1.0000 - val_loss: 0.9490 - val_accuracy: 0.7357\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 3s 138ms/step - loss: 2.8157e-05 - accuracy: 1.0000 - val_loss: 1.0237 - val_accuracy: 0.7286\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 2.4853e-05 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.7286\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 3s 129ms/step - loss: 2.3029e-05 - accuracy: 1.0000 - val_loss: 1.1853 - val_accuracy: 0.7214\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 3s 129ms/step - loss: 2.1183e-05 - accuracy: 1.0000 - val_loss: 1.2825 - val_accuracy: 0.7214\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 3s 129ms/step - loss: 1.8676e-05 - accuracy: 1.0000 - val_loss: 1.3772 - val_accuracy: 0.7214\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 1.7173e-05 - accuracy: 1.0000 - val_loss: 1.4777 - val_accuracy: 0.7214\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 1.6280e-05 - accuracy: 1.0000 - val_loss: 1.5812 - val_accuracy: 0.7214\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 1.4749e-05 - accuracy: 1.0000 - val_loss: 1.6745 - val_accuracy: 0.7214\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 3s 127ms/step - loss: 1.3604e-05 - accuracy: 1.0000 - val_loss: 1.7653 - val_accuracy: 0.7286\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 1.2605e-05 - accuracy: 1.0000 - val_loss: 1.8444 - val_accuracy: 0.7357\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 3s 129ms/step - loss: 1.1572e-05 - accuracy: 1.0000 - val_loss: 1.9267 - val_accuracy: 0.7357\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 3s 128ms/step - loss: 1.0605e-05 - accuracy: 1.0000 - val_loss: 1.9860 - val_accuracy: 0.7357\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 3s 131ms/step - loss: 1.0389e-05 - accuracy: 1.0000 - val_loss: 2.0545 - val_accuracy: 0.7357\n",
            "Epoch 37/100\n",
            "17/23 [=====================>........] - ETA: 0s - loss: 8.9107e-06 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-43b2074b2e00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2= Sequential([\n",
        "    Conv2D(filters=16, kernel_size=(2,2), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    BatchNormalization(name='batchnorm_1'),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,2, activation=\"relu\"),\n",
        "    Conv2D(32,2, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1024, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_2.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_2=model_2.fit(\n",
        "    train_data,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--BmV7sy8KA7",
        "outputId": "0ecafa86-a0e6-44e6-f855-96840211fe7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 9s 257ms/step - loss: 3.2190 - accuracy: 0.2903 - val_loss: 1.9459 - val_accuracy: 0.1429\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 5s 207ms/step - loss: 1.1723 - accuracy: 0.5792 - val_loss: 1.9458 - val_accuracy: 0.1286\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 5s 209ms/step - loss: 0.5432 - accuracy: 0.8219 - val_loss: 1.9391 - val_accuracy: 0.2714\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 0.2608 - accuracy: 0.9173 - val_loss: 1.9389 - val_accuracy: 0.2500\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 0.2140 - accuracy: 0.9453 - val_loss: 1.9411 - val_accuracy: 0.2643\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 0.0923 - accuracy: 0.9762 - val_loss: 1.9166 - val_accuracy: 0.3714\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 5s 212ms/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: 1.8814 - val_accuracy: 0.4429\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 0.0289 - accuracy: 0.9958 - val_loss: 1.8686 - val_accuracy: 0.4571\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 0.0458 - accuracy: 0.9902 - val_loss: 1.8718 - val_accuracy: 0.4571\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 1.7978 - val_accuracy: 0.5214\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 1.7405 - val_accuracy: 0.5429\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 5s 212ms/step - loss: 0.0298 - accuracy: 0.9958 - val_loss: 1.7476 - val_accuracy: 0.6071\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5982 - val_accuracy: 0.6786\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 5s 211ms/step - loss: 7.5121e-04 - accuracy: 1.0000 - val_loss: 1.4441 - val_accuracy: 0.7214\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 4.4505e-04 - accuracy: 1.0000 - val_loss: 1.3038 - val_accuracy: 0.7286\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 5s 207ms/step - loss: 3.1160e-04 - accuracy: 1.0000 - val_loss: 1.1717 - val_accuracy: 0.7571\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 2.5007e-04 - accuracy: 1.0000 - val_loss: 1.0507 - val_accuracy: 0.7643\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 2.0608e-04 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.7571\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 1.7709e-04 - accuracy: 1.0000 - val_loss: 0.8612 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 5s 207ms/step - loss: 1.5249e-04 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.7429\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 1.3934e-04 - accuracy: 1.0000 - val_loss: 0.7578 - val_accuracy: 0.7500\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 5s 207ms/step - loss: 1.2336e-04 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.7571\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 5s 209ms/step - loss: 1.0990e-04 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.7643\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 5s 207ms/step - loss: 1.0114e-04 - accuracy: 1.0000 - val_loss: 0.7489 - val_accuracy: 0.7643\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 9.1015e-05 - accuracy: 1.0000 - val_loss: 0.7768 - val_accuracy: 0.7643\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 8.3634e-05 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.7643\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 5s 209ms/step - loss: 7.7156e-05 - accuracy: 1.0000 - val_loss: 0.8606 - val_accuracy: 0.7643\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 5s 209ms/step - loss: 7.1176e-05 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.7714\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 5s 209ms/step - loss: 6.6079e-05 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.7714\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 6.1119e-05 - accuracy: 1.0000 - val_loss: 1.0215 - val_accuracy: 0.7714\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 5s 209ms/step - loss: 5.6757e-05 - accuracy: 1.0000 - val_loss: 1.0750 - val_accuracy: 0.7714\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 5.3181e-05 - accuracy: 1.0000 - val_loss: 1.1283 - val_accuracy: 0.7714\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 4.9827e-05 - accuracy: 1.0000 - val_loss: 1.1770 - val_accuracy: 0.7714\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 4.6878e-05 - accuracy: 1.0000 - val_loss: 1.2218 - val_accuracy: 0.7786\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 4.4595e-05 - accuracy: 1.0000 - val_loss: 1.2628 - val_accuracy: 0.7786\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 4.1919e-05 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.7714\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 5s 211ms/step - loss: 4.0036e-05 - accuracy: 1.0000 - val_loss: 1.3308 - val_accuracy: 0.7714\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 5s 207ms/step - loss: 3.7275e-05 - accuracy: 1.0000 - val_loss: 1.3581 - val_accuracy: 0.7714\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 3.5575e-05 - accuracy: 1.0000 - val_loss: 1.3819 - val_accuracy: 0.7714\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 5s 207ms/step - loss: 3.3953e-05 - accuracy: 1.0000 - val_loss: 1.4035 - val_accuracy: 0.7714\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 3.1905e-05 - accuracy: 1.0000 - val_loss: 1.4218 - val_accuracy: 0.7714\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 3.0645e-05 - accuracy: 1.0000 - val_loss: 1.4362 - val_accuracy: 0.7714\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 2.9126e-05 - accuracy: 1.0000 - val_loss: 1.4499 - val_accuracy: 0.7714\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 2.7881e-05 - accuracy: 1.0000 - val_loss: 1.4614 - val_accuracy: 0.7714\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 5s 209ms/step - loss: 2.6558e-05 - accuracy: 1.0000 - val_loss: 1.4719 - val_accuracy: 0.7714\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 2.5264e-05 - accuracy: 1.0000 - val_loss: 1.4822 - val_accuracy: 0.7714\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 2.4131e-05 - accuracy: 1.0000 - val_loss: 1.4908 - val_accuracy: 0.7714\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 2.3243e-05 - accuracy: 1.0000 - val_loss: 1.4992 - val_accuracy: 0.7714\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 2.2391e-05 - accuracy: 1.0000 - val_loss: 1.5060 - val_accuracy: 0.7714\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 5s 208ms/step - loss: 2.1648e-05 - accuracy: 1.0000 - val_loss: 1.5127 - val_accuracy: 0.7643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVX8wpYMA-MI",
        "outputId": "d8ba961e-84d9-497d-cea7-b4fa220d082e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 239, 239, 16)      80        \n",
            "                                                                 \n",
            " batchnorm_1 (BatchNormaliza  (None, 239, 239, 16)     64        \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 237, 237, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 118, 118, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 117, 117, 32)      4128      \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 116, 116, 32)      4128      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 58, 58, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 107648)            0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1024)              110232576 \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 7)                 7175      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 110,252,791\n",
            "Trainable params: 110,252,759\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3= Sequential([\n",
        "    Conv2D(filters=20, kernel_size=(2,2), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    Conv2D(40,2, activation=\"relu\"),\n",
        "    BatchNormalization(name='batchnorm_1'),\n",
        "    Conv2D(256,2, activation=\"relu\"),\n",
        "    Conv2D(256,2, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(400, activation=\"relu\"),\n",
        "    Dense(400, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_3.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_3=model_3.fit(\n",
        "    train_data,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT0T0tVtAwRA",
        "outputId": "098e961b-9de9-4e83-8ec6-9af17d2f5e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 7s 212ms/step - loss: 1.9015 - accuracy: 0.1950 - val_loss: 1.9428 - val_accuracy: 0.1857\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 4s 179ms/step - loss: 1.4337 - accuracy: 0.4811 - val_loss: 1.8748 - val_accuracy: 0.3786\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 0.9376 - accuracy: 0.6578 - val_loss: 1.8503 - val_accuracy: 0.5071\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.6302 - accuracy: 0.7644 - val_loss: 1.8537 - val_accuracy: 0.4786\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 4s 178ms/step - loss: 0.3929 - accuracy: 0.8597 - val_loss: 1.7967 - val_accuracy: 0.5714\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 0.2001 - accuracy: 0.9299 - val_loss: 1.5383 - val_accuracy: 0.5786\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 4s 178ms/step - loss: 0.1938 - accuracy: 0.9299 - val_loss: 1.6936 - val_accuracy: 0.5929\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0584 - accuracy: 0.9846 - val_loss: 1.3101 - val_accuracy: 0.6571\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 4s 178ms/step - loss: 0.0809 - accuracy: 0.9776 - val_loss: 1.3728 - val_accuracy: 0.6000\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.1219 - accuracy: 0.9635 - val_loss: 1.3741 - val_accuracy: 0.6143\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 4s 178ms/step - loss: 0.0107 - accuracy: 0.9986 - val_loss: 1.0853 - val_accuracy: 0.7000\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0542 - accuracy: 0.9874 - val_loss: 1.2136 - val_accuracy: 0.6286\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 1.2240 - val_accuracy: 0.6286\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 0.0561 - accuracy: 0.9846 - val_loss: 1.2721 - val_accuracy: 0.5786\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 4s 178ms/step - loss: 0.0379 - accuracy: 0.9860 - val_loss: 1.0995 - val_accuracy: 0.6714\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 4s 178ms/step - loss: 0.0297 - accuracy: 0.9902 - val_loss: 1.0941 - val_accuracy: 0.6714\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 1.0073 - val_accuracy: 0.6500\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 4s 175ms/step - loss: 0.0654 - accuracy: 0.9790 - val_loss: 1.1806 - val_accuracy: 0.6643\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0465 - accuracy: 0.9874 - val_loss: 1.0572 - val_accuracy: 0.6643\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 0.0341 - accuracy: 0.9916 - val_loss: 1.0815 - val_accuracy: 0.6857\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 1.0974 - val_accuracy: 0.6643\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 0.0391 - accuracy: 0.9832 - val_loss: 1.1349 - val_accuracy: 0.6714\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.1248 - accuracy: 0.9677 - val_loss: 1.1036 - val_accuracy: 0.6357\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 1.3780 - val_accuracy: 0.5643\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0280 - accuracy: 0.9874 - val_loss: 1.4259 - val_accuracy: 0.5214\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 0.0679 - accuracy: 0.9846 - val_loss: 1.1809 - val_accuracy: 0.6643\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0515 - accuracy: 0.9832 - val_loss: 1.4463 - val_accuracy: 0.6786\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.0147 - accuracy: 0.9944 - val_loss: 1.7057 - val_accuracy: 0.6643\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 1.4635 - val_accuracy: 0.6786\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 4s 182ms/step - loss: 0.0027 - accuracy: 0.9986 - val_loss: 1.6133 - val_accuracy: 0.6929\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8343 - val_accuracy: 0.7071\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 4s 175ms/step - loss: 1.3936e-04 - accuracy: 1.0000 - val_loss: 2.0530 - val_accuracy: 0.7214\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 1.4144e-04 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.7214\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 3.9130e-05 - accuracy: 1.0000 - val_loss: 2.2631 - val_accuracy: 0.7143\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 4s 181ms/step - loss: 3.0884e-05 - accuracy: 1.0000 - val_loss: 2.3744 - val_accuracy: 0.7214\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 2.7785e-05 - accuracy: 1.0000 - val_loss: 2.4713 - val_accuracy: 0.7071\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 2.4065e-05 - accuracy: 1.0000 - val_loss: 2.5553 - val_accuracy: 0.7143\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 4s 175ms/step - loss: 2.3040e-05 - accuracy: 1.0000 - val_loss: 2.6266 - val_accuracy: 0.7143\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 2.0326e-05 - accuracy: 1.0000 - val_loss: 2.6869 - val_accuracy: 0.7143\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 1.9157e-05 - accuracy: 1.0000 - val_loss: 2.7379 - val_accuracy: 0.7143\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 1.7196e-05 - accuracy: 1.0000 - val_loss: 2.7821 - val_accuracy: 0.7143\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 1.6516e-05 - accuracy: 1.0000 - val_loss: 2.8198 - val_accuracy: 0.7143\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 1.4955e-05 - accuracy: 1.0000 - val_loss: 2.8514 - val_accuracy: 0.7143\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 4s 175ms/step - loss: 1.4124e-05 - accuracy: 1.0000 - val_loss: 2.8778 - val_accuracy: 0.7143\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 1.3089e-05 - accuracy: 1.0000 - val_loss: 2.9014 - val_accuracy: 0.7143\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 1.2068e-05 - accuracy: 1.0000 - val_loss: 2.9205 - val_accuracy: 0.7143\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 1.1387e-05 - accuracy: 1.0000 - val_loss: 2.9376 - val_accuracy: 0.7143\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 1.0785e-05 - accuracy: 1.0000 - val_loss: 2.9521 - val_accuracy: 0.7143\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 1.0175e-05 - accuracy: 1.0000 - val_loss: 2.9640 - val_accuracy: 0.7143\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 1.0512e-05 - accuracy: 1.0000 - val_loss: 2.9768 - val_accuracy: 0.7143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8BS8au5CcI_",
        "outputId": "9190f6c1-b271-4ec6-8d90-e9cc328b04a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 62, 62, 20)        200       \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 31, 31, 20)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 29, 29, 50)        9050      \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 14, 14, 50)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 9800)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 500)               4900500   \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 7)                 3507      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,913,257\n",
            "Trainable params: 4,913,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wny0gFLwCfZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}