{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DuyguHistogramModelDenemeleri.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Fonksyonlar"
      ],
      "metadata": {
        "id": "z0J6tWPNeQDH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "729jyraceLqD"
      },
      "outputs": [],
      "source": [
        "def load_and_prep_image(filename, img_shape=64, colour_channel=\"grayscale\"):\n",
        "  #Read image\n",
        "  img = tf.io.read_file(filename)\n",
        "  #Decode the read file\n",
        "  img= tf.image.decode_image(img)\n",
        "  #Resize the image\n",
        "  img= tf.image.resize(img,size=[img_shape,img_shape])\n",
        "  #Scaling the image\n",
        "  img=tf.image.rgb_to_grayscale(img, name=None)\n",
        "  img= img/255.\n",
        "  return img\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \n",
        "  #import the target image and pre process it\n",
        "  img= load_and_prep_image(filename)\n",
        "\n",
        "  #make predictions\n",
        "  pred = model.predict(tf.expand_dims(img,axis=0))\n",
        "\n",
        "  #Get the predicted class\n",
        "  pred_class= class_names[int(tf.round(pred.argmax()))]\n",
        "  #plot the image and predicted class\n",
        " ##### ? plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.imshow(img)\n",
        "  plt.axis(\"off\")\n",
        "  print(pred_class, pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(history):\n",
        "  \n",
        "  loss= history.history[\"loss\"]\n",
        "  val_loss=history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "  epo= range(len(history.history[\"loss\"]))\n",
        "  \n",
        "\n",
        "  plt.plot(epo, loss, label=\"Training_Loss\")\n",
        "  plt.plot(epo, val_loss, label=\"val_Loss\")\n",
        "  plt.title=(\"Loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(epo, accuracy, label=\"Training_accuracy\")\n",
        "  plt.plot(epo, val_accuracy, label=\"val_accuracy\")\n",
        "  plt.title=(\"accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "5uwo9SdbeUVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# İmage Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "    #Setup Target Directory\n",
        "    target_folder= target_dir+\"/\"+target_class\n",
        "    \n",
        "    #Get Random İmage\n",
        "    random_image= random.sample(os.listdir(target_folder),1)\n",
        "    print(random_image)\n",
        "    #Read in the image and plot it using matplotlib\n",
        "    img = mpimg.imread(target_folder+\"/\"+random_image[0])\n",
        "    plt.imshow(img)\n",
        "    plt.title(target_class)\n",
        "    plt.axis(\"off\");\n",
        "    \n",
        "    print(f\"Image shape: {img.shape}\")\n",
        "    \n",
        "    return img"
      ],
      "metadata": {
        "id": "jeJphv8Bemxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#THE CONFUSION MATRIX\n",
        "#-------------------------------------------------\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def PrettyConfusionMatrix(y_true,y_pred,classes=None,figsize=(10,10),text_size=15 ):\n",
        "\n",
        "    cm=confusion_matrix(y_true,y_pred)\n",
        "    cm_norm=cm.astype(\"float\")/cm.sum(axis=1)[:,np.newaxis]\n",
        "    n_classes=cm.shape[0]\n",
        "\n",
        "    #Making prettify\n",
        "    fig, ax= plt.subplots(figsize=figsize)\n",
        "    # Create matrix Plot\n",
        "    cax=ax.matshow(cm,cmap=plt.cm.Blues)\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    #Create clases\n",
        "\n",
        "    if classes:\n",
        "        labels=classes\n",
        "    else:\n",
        "        labels=np.arange(cm.shape[0])\n",
        "\n",
        "    #axis labeling\n",
        "    ax.set(title=\"Confusion Matrix\",\n",
        "          xlabel=\"Predicted Label\",\n",
        "          ylabel=\"True Label\",\n",
        "          xticks=np.arange(n_classes),\n",
        "          yticks=np.arange(n_classes),\n",
        "          xticklabels=labels,\n",
        "          yticklabels=labels)\n",
        "    #Set x axis to bottom\n",
        "    ax.xaxis.set_label_position(\"bottom\")\n",
        "    ax.xaxis.tick_bottom()\n",
        "\n",
        "    #Adjust  label size\n",
        "    ax.yaxis.label.set_size(text_size)\n",
        "    ax.xaxis.label.set_size(text_size)\n",
        "    ax.title.set_size(text_size+10)\n",
        "    #set thresh hold for different Colours\n",
        "    threshold= (cm.max()+cm.min())/2\n",
        "\n",
        "    #Plot the text on each cell\n",
        "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "        plt.text(j,i,f\"{cm[i,j]} ({cm_norm[i,j]*100:.1f}%)\",\n",
        "                horizontalalignment= \"center\",\n",
        "                color=\"white\"  if cm[i,j]>threshold else \"black\",\n",
        "                size=15)"
      ],
      "metadata": {
        "id": "yvI86vjfepBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Images"
      ],
      "metadata": {
        "id": "OOxDG4pXes1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref= zipfile.ZipFile(\"Histogram_Datas_Upload.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "8K_hnHu-erDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "#walkthrough all classes\n",
        "for dirpath,dirnames , filenames in os.walk(\"Histogram_Datas_Upload\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEDM0Hdme6Z1",
        "outputId": "101c39fa-7387-4683-855b-c72482a727b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in 'Histogram_Datas_Upload'.\n",
            "There are 7 directories and 0 images in 'Histogram_Datas_Upload/test'.\n",
            "There are 0 directories and 18 images in 'Histogram_Datas_Upload/test/fear'.\n",
            "There are 0 directories and 18 images in 'Histogram_Datas_Upload/test/happy'.\n",
            "There are 0 directories and 18 images in 'Histogram_Datas_Upload/test/sad'.\n",
            "There are 0 directories and 18 images in 'Histogram_Datas_Upload/test/surprised'.\n",
            "There are 0 directories and 18 images in 'Histogram_Datas_Upload/test/angry'.\n",
            "There are 0 directories and 18 images in 'Histogram_Datas_Upload/test/neutral'.\n",
            "There are 0 directories and 18 images in 'Histogram_Datas_Upload/test/disgust'.\n",
            "There are 7 directories and 0 images in 'Histogram_Datas_Upload/train'.\n",
            "There are 0 directories and 105 images in 'Histogram_Datas_Upload/train/fear'.\n",
            "There are 0 directories and 105 images in 'Histogram_Datas_Upload/train/happy'.\n",
            "There are 0 directories and 104 images in 'Histogram_Datas_Upload/train/sad'.\n",
            "There are 0 directories and 103 images in 'Histogram_Datas_Upload/train/surprised'.\n",
            "There are 0 directories and 104 images in 'Histogram_Datas_Upload/train/angry'.\n",
            "There are 0 directories and 104 images in 'Histogram_Datas_Upload/train/neutral'.\n",
            "There are 0 directories and 102 images in 'Histogram_Datas_Upload/train/disgust'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup train and test directories\n",
        "train_dir=\"Histogram_Datas_Upload/train/\"\n",
        "test_dir=\"Histogram_Datas_Upload/test/\"\n",
        "#Lets get the class names\n",
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "data_dir= pathlib.Path(train_dir)\n",
        "class_names= np.array(sorted(item.name for item in data_dir.glob(\"*\")))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1T579Cce8Ul",
        "outputId": "8bd326a1-2f6e-421e-c132-0c0483130195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprised']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "IMG_size= 64\n",
        "#Rescale\n",
        "train_datagen= ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen= ImageDataGenerator(rescale= 1/255.)\n",
        "\n",
        "#load data from directories\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                                 target_size=(IMG_size,IMG_size),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                               color_mode= \"grayscale\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                                 target_size=(IMG_size,IMG_size),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                             color_mode= \"grayscale\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYBWost6e8Gl",
        "outputId": "911063a8-a636-4d8c-bebf-f4cddb4f3dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 727 images belonging to 7 classes.\n",
            "Found 126 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense,Flatten, Conv2D, MaxPool2D,BatchNormalization, Activation\n",
        "from tensorflow.keras import Sequential"
      ],
      "metadata": {
        "id": "y6cZ_Dazfyna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelller"
      ],
      "metadata": {
        "id": "i3YRCqM0f68k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_17= Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    BatchNormalization(name='batchnorm_1'),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(16,3, activation=\"relu\"),\n",
        "    Conv2D(16,5, activation=\"relu\"),\n",
        "    BatchNormalization(name='batchnorm_2'),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(40, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_17.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_17=model_17.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckOmCZ5yf6Ig",
        "outputId": "1a5fa66f-5d27-45fe-9aa6-6c0abfd91c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 22s 370ms/step - loss: 2.8387 - accuracy: 0.1320 - val_loss: 1.9458 - val_accuracy: 0.1429\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.9332 - accuracy: 0.1609 - val_loss: 1.9435 - val_accuracy: 0.1905\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.9098 - accuracy: 0.1527 - val_loss: 1.9312 - val_accuracy: 0.1587\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 5s 230ms/step - loss: 1.8774 - accuracy: 0.1774 - val_loss: 1.9251 - val_accuracy: 0.1508\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.8517 - accuracy: 0.2338 - val_loss: 1.9136 - val_accuracy: 0.2540\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.8076 - accuracy: 0.2531 - val_loss: 1.9268 - val_accuracy: 0.1429\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.7709 - accuracy: 0.2600 - val_loss: 1.9042 - val_accuracy: 0.2063\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.7376 - accuracy: 0.2448 - val_loss: 1.9388 - val_accuracy: 0.1429\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.7082 - accuracy: 0.2655 - val_loss: 2.0453 - val_accuracy: 0.1429\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.6850 - accuracy: 0.2710 - val_loss: 1.8987 - val_accuracy: 0.1587\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 5s 239ms/step - loss: 1.6728 - accuracy: 0.2751 - val_loss: 2.0141 - val_accuracy: 0.1429\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.6476 - accuracy: 0.2806 - val_loss: 2.3652 - val_accuracy: 0.1429\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.6351 - accuracy: 0.2806 - val_loss: 2.0843 - val_accuracy: 0.1429\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 6s 248ms/step - loss: 1.6274 - accuracy: 0.2820 - val_loss: 1.8970 - val_accuracy: 0.1825\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.6064 - accuracy: 0.2957 - val_loss: 2.1757 - val_accuracy: 0.1429\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.5904 - accuracy: 0.2930 - val_loss: 2.1747 - val_accuracy: 0.1508\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.5810 - accuracy: 0.2957 - val_loss: 1.8484 - val_accuracy: 0.2143\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.5628 - accuracy: 0.2999 - val_loss: 2.4387 - val_accuracy: 0.1508\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.5489 - accuracy: 0.3026 - val_loss: 2.4955 - val_accuracy: 0.1667\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.5586 - accuracy: 0.3012 - val_loss: 1.8779 - val_accuracy: 0.2063\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.5507 - accuracy: 0.3081 - val_loss: 2.0481 - val_accuracy: 0.1905\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.5324 - accuracy: 0.2957 - val_loss: 1.7084 - val_accuracy: 0.2698\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.5302 - accuracy: 0.3164 - val_loss: 1.6155 - val_accuracy: 0.3095\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.5040 - accuracy: 0.3164 - val_loss: 1.6702 - val_accuracy: 0.3016\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.4947 - accuracy: 0.3081 - val_loss: 1.7265 - val_accuracy: 0.2857\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.4813 - accuracy: 0.3205 - val_loss: 1.7522 - val_accuracy: 0.2937\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.4823 - accuracy: 0.3150 - val_loss: 1.6844 - val_accuracy: 0.2857\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 6s 240ms/step - loss: 1.4911 - accuracy: 0.3040 - val_loss: 1.7817 - val_accuracy: 0.2857\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 5s 230ms/step - loss: 1.5172 - accuracy: 0.3177 - val_loss: 1.5555 - val_accuracy: 0.3095\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.4895 - accuracy: 0.3150 - val_loss: 1.6079 - val_accuracy: 0.3333\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.4749 - accuracy: 0.3260 - val_loss: 1.6132 - val_accuracy: 0.3333\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.4560 - accuracy: 0.3287 - val_loss: 1.5435 - val_accuracy: 0.3016\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.4376 - accuracy: 0.3260 - val_loss: 1.7646 - val_accuracy: 0.2460\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 5s 226ms/step - loss: 1.4334 - accuracy: 0.3315 - val_loss: 1.5545 - val_accuracy: 0.3413\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.4448 - accuracy: 0.3411 - val_loss: 1.5353 - val_accuracy: 0.3254\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.4380 - accuracy: 0.3356 - val_loss: 1.5511 - val_accuracy: 0.3333\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.4247 - accuracy: 0.3466 - val_loss: 1.5432 - val_accuracy: 0.3571\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.3996 - accuracy: 0.3274 - val_loss: 1.5087 - val_accuracy: 0.3333\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.3877 - accuracy: 0.3659 - val_loss: 1.5023 - val_accuracy: 0.3413\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3771 - accuracy: 0.3398 - val_loss: 1.5526 - val_accuracy: 0.3254\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.3744 - accuracy: 0.3425 - val_loss: 1.5126 - val_accuracy: 0.3095\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3677 - accuracy: 0.3590 - val_loss: 1.5309 - val_accuracy: 0.3492\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.3604 - accuracy: 0.3631 - val_loss: 1.5277 - val_accuracy: 0.3254\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3568 - accuracy: 0.3645 - val_loss: 1.5278 - val_accuracy: 0.3095\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.3563 - accuracy: 0.3783 - val_loss: 1.5786 - val_accuracy: 0.3492\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 5s 230ms/step - loss: 1.3504 - accuracy: 0.3741 - val_loss: 1.5750 - val_accuracy: 0.3730\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.3478 - accuracy: 0.4085 - val_loss: 1.6194 - val_accuracy: 0.3492\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 6s 240ms/step - loss: 1.3654 - accuracy: 0.3645 - val_loss: 1.5442 - val_accuracy: 0.3175\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 5s 237ms/step - loss: 1.4407 - accuracy: 0.3645 - val_loss: 1.5552 - val_accuracy: 0.3016\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.4343 - accuracy: 0.3508 - val_loss: 1.5863 - val_accuracy: 0.2937\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 5s 231ms/step - loss: 1.3759 - accuracy: 0.3783 - val_loss: 1.5315 - val_accuracy: 0.3016\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3664 - accuracy: 0.3604 - val_loss: 1.5433 - val_accuracy: 0.3095\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.4257 - accuracy: 0.3508 - val_loss: 1.7059 - val_accuracy: 0.2540\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.4577 - accuracy: 0.3232 - val_loss: 1.6157 - val_accuracy: 0.3175\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3818 - accuracy: 0.3728 - val_loss: 1.5363 - val_accuracy: 0.3571\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.3437 - accuracy: 0.3714 - val_loss: 1.5249 - val_accuracy: 0.3810\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3295 - accuracy: 0.3920 - val_loss: 1.4824 - val_accuracy: 0.3492\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3214 - accuracy: 0.4127 - val_loss: 1.5299 - val_accuracy: 0.3571\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.3140 - accuracy: 0.3865 - val_loss: 1.4603 - val_accuracy: 0.3571\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.3190 - accuracy: 0.4030 - val_loss: 1.6013 - val_accuracy: 0.3095\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3168 - accuracy: 0.4099 - val_loss: 1.6131 - val_accuracy: 0.3571\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3143 - accuracy: 0.3975 - val_loss: 1.6241 - val_accuracy: 0.3254\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.3059 - accuracy: 0.4058 - val_loss: 1.6242 - val_accuracy: 0.3333\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2980 - accuracy: 0.4195 - val_loss: 1.6387 - val_accuracy: 0.3413\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 5s 230ms/step - loss: 1.2959 - accuracy: 0.4250 - val_loss: 1.5216 - val_accuracy: 0.3254\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2903 - accuracy: 0.4292 - val_loss: 1.4641 - val_accuracy: 0.3651\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 5s 237ms/step - loss: 1.2967 - accuracy: 0.4168 - val_loss: 2.0394 - val_accuracy: 0.3254\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 5s 235ms/step - loss: 1.3286 - accuracy: 0.3975 - val_loss: 1.6620 - val_accuracy: 0.3016\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 6s 246ms/step - loss: 1.3238 - accuracy: 0.3673 - val_loss: 1.5493 - val_accuracy: 0.3571\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 6s 239ms/step - loss: 1.3936 - accuracy: 0.3851 - val_loss: 1.7849 - val_accuracy: 0.3571\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 5s 239ms/step - loss: 1.3422 - accuracy: 0.3824 - val_loss: 1.5313 - val_accuracy: 0.3492\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 5s 237ms/step - loss: 1.3371 - accuracy: 0.3948 - val_loss: 1.5037 - val_accuracy: 0.3095\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 6s 237ms/step - loss: 1.3031 - accuracy: 0.3906 - val_loss: 1.6032 - val_accuracy: 0.3571\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 6s 241ms/step - loss: 1.2829 - accuracy: 0.4292 - val_loss: 1.5892 - val_accuracy: 0.3492\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2701 - accuracy: 0.4498 - val_loss: 1.4763 - val_accuracy: 0.3810\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2777 - accuracy: 0.4278 - val_loss: 1.4815 - val_accuracy: 0.3413\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2727 - accuracy: 0.4360 - val_loss: 1.4960 - val_accuracy: 0.3492\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2656 - accuracy: 0.4402 - val_loss: 1.4963 - val_accuracy: 0.3413\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2568 - accuracy: 0.4580 - val_loss: 1.4822 - val_accuracy: 0.3333\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2615 - accuracy: 0.4608 - val_loss: 1.4939 - val_accuracy: 0.3254\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 5s 229ms/step - loss: 1.2549 - accuracy: 0.4305 - val_loss: 1.6132 - val_accuracy: 0.3492\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2571 - accuracy: 0.4498 - val_loss: 1.6360 - val_accuracy: 0.3651\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2493 - accuracy: 0.4635 - val_loss: 1.4770 - val_accuracy: 0.3492\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2492 - accuracy: 0.4443 - val_loss: 1.5149 - val_accuracy: 0.3492\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2452 - accuracy: 0.4402 - val_loss: 1.4717 - val_accuracy: 0.3175\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2456 - accuracy: 0.4580 - val_loss: 1.5138 - val_accuracy: 0.3651\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2481 - accuracy: 0.4594 - val_loss: 1.5511 - val_accuracy: 0.3254\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 6s 248ms/step - loss: 1.3086 - accuracy: 0.3961 - val_loss: 1.5760 - val_accuracy: 0.3333\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 5s 230ms/step - loss: 1.2809 - accuracy: 0.3989 - val_loss: 1.5070 - val_accuracy: 0.3333\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 6s 239ms/step - loss: 1.2590 - accuracy: 0.4512 - val_loss: 1.5352 - val_accuracy: 0.3333\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 5s 234ms/step - loss: 1.2581 - accuracy: 0.4250 - val_loss: 1.5241 - val_accuracy: 0.3333\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2548 - accuracy: 0.4237 - val_loss: 1.6403 - val_accuracy: 0.3175\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2499 - accuracy: 0.4319 - val_loss: 1.4939 - val_accuracy: 0.3651\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2349 - accuracy: 0.4787 - val_loss: 1.4910 - val_accuracy: 0.3730\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2381 - accuracy: 0.4525 - val_loss: 1.5001 - val_accuracy: 0.3492\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 5s 227ms/step - loss: 1.2418 - accuracy: 0.4305 - val_loss: 1.5729 - val_accuracy: 0.3571\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2305 - accuracy: 0.4663 - val_loss: 1.7203 - val_accuracy: 0.3413\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 5s 228ms/step - loss: 1.2436 - accuracy: 0.4429 - val_loss: 1.6849 - val_accuracy: 0.3254\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 5s 231ms/step - loss: 1.2486 - accuracy: 0.4388 - val_loss: 1.5307 - val_accuracy: 0.3413\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 6s 244ms/step - loss: 1.2547 - accuracy: 0.4319 - val_loss: 1.4886 - val_accuracy: 0.3254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "CvNLbIL8iY9i",
        "outputId": "aa125f33-6ed3-4781-9ad1-0996f6fad14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_size= 224\n",
        "#Rescale\n",
        "train_datagen= ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen= ImageDataGenerator(rescale= 1/255.)\n",
        "\n",
        "#load data from directories\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                                 target_size=(IMG_size,IMG_size),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                               color_mode= \"grayscale\",\n",
        "                                               shuffle= True)\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                                 target_size=(IMG_size,IMG_size),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                             color_mode= \"grayscale\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRD-Jx61gLRa",
        "outputId": "8bdbe2cd-dd3b-484b-a2ef-20fa57b8bef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 727 images belonging to 7 classes.\n",
            "Found 126 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_17= Sequential([\n",
        "    Conv2D(filters=64, kernel_size=(5,5), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    BatchNormalization(name='batchnorm_1'),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    BatchNormalization(name='batchnorm_2'),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(100, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_17.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_17=model_17.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77ceDCAthqqY",
        "outputId": "c00607f1-e1e3-4482-df9a-98f18ba4a4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 4s 90ms/step - loss: 1.9095 - accuracy: 0.2435 - val_loss: 1.9394 - val_accuracy: 0.2063\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3876 - accuracy: 0.4897 - val_loss: 1.9542 - val_accuracy: 0.1429\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.0642 - accuracy: 0.5970 - val_loss: 2.0354 - val_accuracy: 0.1429\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.8966 - accuracy: 0.6850 - val_loss: 2.2036 - val_accuracy: 0.1825\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.7112 - accuracy: 0.7373 - val_loss: 2.3344 - val_accuracy: 0.1825\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.5538 - accuracy: 0.8033 - val_loss: 2.7181 - val_accuracy: 0.1429\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4643 - accuracy: 0.8542 - val_loss: 3.2996 - val_accuracy: 0.1429\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.3388 - accuracy: 0.8955 - val_loss: 2.8125 - val_accuracy: 0.1429\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.2811 - accuracy: 0.9147 - val_loss: 2.8464 - val_accuracy: 0.1905\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.1798 - accuracy: 0.9519 - val_loss: 2.6803 - val_accuracy: 0.1667\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.1871 - accuracy: 0.9436 - val_loss: 2.5180 - val_accuracy: 0.2937\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.1619 - accuracy: 0.9532 - val_loss: 3.2916 - val_accuracy: 0.1984\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.1071 - accuracy: 0.9697 - val_loss: 2.9538 - val_accuracy: 0.1984\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.0569 - accuracy: 0.9904 - val_loss: 2.5865 - val_accuracy: 0.2698\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.0381 - accuracy: 0.9945 - val_loss: 2.0681 - val_accuracy: 0.3095\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.0329 - accuracy: 0.9931 - val_loss: 1.8651 - val_accuracy: 0.3889\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.0186 - accuracy: 0.9986 - val_loss: 1.8500 - val_accuracy: 0.3730\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.8070 - val_accuracy: 0.4127\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6254 - val_accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4718 - val_accuracy: 0.5556\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3207 - val_accuracy: 0.6032\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1892 - val_accuracy: 0.6429\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0028 - val_accuracy: 0.6984\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9178 - val_accuracy: 0.7063\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8795 - val_accuracy: 0.7381\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8183 - val_accuracy: 0.7540\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.7698\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.7857\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 0.7937\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.7937\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 9.4139e-04 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.8016\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 8.7692e-04 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8095\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 8.4585e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8095\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 7.7039e-04 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8254\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 7.3124e-04 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8492\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 6.8632e-04 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8492\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 6.4204e-04 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8492\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 6.2810e-04 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.8571\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 5.9177e-04 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8571\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 5.7003e-04 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.8571\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 5.3584e-04 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8492\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 5.1158e-04 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8651\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 4.9615e-04 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8571\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 4.6008e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8651\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 4.4510e-04 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.8571\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 4.2742e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8651\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 4.0694e-04 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.8651\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 3.9499e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8651\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 3.7778e-04 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.8651\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 3.6264e-04 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8651\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 3.4938e-04 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.8571\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 3.3666e-04 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.8651\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 3.2415e-04 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.8651\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 3.1067e-04 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.8571\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 2.9850e-04 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.8651\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 2.8635e-04 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.8651\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 2.7163e-04 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.8651\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 2.7278e-04 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.8571\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 2.5787e-04 - accuracy: 1.0000 - val_loss: 0.7344 - val_accuracy: 0.8651\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 2.4600e-04 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.8651\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 2.4574e-04 - accuracy: 1.0000 - val_loss: 0.7355 - val_accuracy: 0.8571\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 2.3554e-04 - accuracy: 1.0000 - val_loss: 0.7403 - val_accuracy: 0.8651\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 2.2565e-04 - accuracy: 1.0000 - val_loss: 0.7404 - val_accuracy: 0.8571\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 2.2428e-04 - accuracy: 1.0000 - val_loss: 0.7344 - val_accuracy: 0.8651\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 2.1855e-04 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.8571\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 2.0474e-04 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8651\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9781e-04 - accuracy: 1.0000 - val_loss: 0.7452 - val_accuracy: 0.8651\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9166e-04 - accuracy: 1.0000 - val_loss: 0.7440 - val_accuracy: 0.8571\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.8365e-04 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.8651\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.8291e-04 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8651\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.7385e-04 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.8651\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.6814e-04 - accuracy: 1.0000 - val_loss: 0.7586 - val_accuracy: 0.8571\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.6981e-04 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.8651\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.6189e-04 - accuracy: 1.0000 - val_loss: 0.7543 - val_accuracy: 0.8651\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.5745e-04 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.8651\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.4979e-04 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8571\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4521e-04 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.8651\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.4422e-04 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8571\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.4080e-04 - accuracy: 1.0000 - val_loss: 0.7699 - val_accuracy: 0.8492\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3550e-04 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.8571\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.3139e-04 - accuracy: 1.0000 - val_loss: 0.7705 - val_accuracy: 0.8492\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.3070e-04 - accuracy: 1.0000 - val_loss: 0.7654 - val_accuracy: 0.8651\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2632e-04 - accuracy: 1.0000 - val_loss: 0.7663 - val_accuracy: 0.8651\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.2323e-04 - accuracy: 1.0000 - val_loss: 0.7742 - val_accuracy: 0.8571\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1776e-04 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8571\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.1736e-04 - accuracy: 1.0000 - val_loss: 0.7701 - val_accuracy: 0.8651\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1386e-04 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.8651\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0928e-04 - accuracy: 1.0000 - val_loss: 0.7774 - val_accuracy: 0.8571\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0899e-04 - accuracy: 1.0000 - val_loss: 0.7712 - val_accuracy: 0.8571\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0679e-04 - accuracy: 1.0000 - val_loss: 0.7782 - val_accuracy: 0.8651\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 1.0415e-04 - accuracy: 1.0000 - val_loss: 0.7781 - val_accuracy: 0.8651\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 9.9791e-05 - accuracy: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.8651\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 9.7754e-05 - accuracy: 1.0000 - val_loss: 0.7782 - val_accuracy: 0.8651\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 9.5741e-05 - accuracy: 1.0000 - val_loss: 0.7797 - val_accuracy: 0.8651\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 9.3287e-05 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.8571\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 9.0281e-05 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.8571\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 9.0360e-05 - accuracy: 1.0000 - val_loss: 0.7836 - val_accuracy: 0.8651\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 8.6725e-05 - accuracy: 1.0000 - val_loss: 0.7857 - val_accuracy: 0.8492\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 8.5416e-05 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.8492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_14= Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    BatchNormalization(name='batchnorm_1'),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    Conv2D(32,3, activation=\"tanh\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_14.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_14=model_14.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpXRe-JnjHLB",
        "outputId": "efe073f6-b90e-49d8-a2f2-bdfe432beb3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 4s 106ms/step - loss: 1.9061 - accuracy: 0.2173 - val_loss: 1.9390 - val_accuracy: 0.1746\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 1.4392 - accuracy: 0.4525 - val_loss: 1.8503 - val_accuracy: 0.4127\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 1.1017 - accuracy: 0.5846 - val_loss: 1.8370 - val_accuracy: 0.2937\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 0.8710 - accuracy: 0.6781 - val_loss: 1.6090 - val_accuracy: 0.4841\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.7748 - accuracy: 0.6988 - val_loss: 1.6166 - val_accuracy: 0.4683\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.6272 - accuracy: 0.7689 - val_loss: 1.4185 - val_accuracy: 0.5952\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.4980 - accuracy: 0.8184 - val_loss: 1.2640 - val_accuracy: 0.6429\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.4209 - accuracy: 0.8624 - val_loss: 1.1418 - val_accuracy: 0.6190\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.3703 - accuracy: 0.8735 - val_loss: 1.0224 - val_accuracy: 0.7063\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.2718 - accuracy: 0.9175 - val_loss: 0.9769 - val_accuracy: 0.6667\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.1787 - accuracy: 0.9505 - val_loss: 0.8085 - val_accuracy: 0.7698\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.1415 - accuracy: 0.9711 - val_loss: 0.8621 - val_accuracy: 0.6508\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.1031 - accuracy: 0.9780 - val_loss: 0.8210 - val_accuracy: 0.7222\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0572 - accuracy: 0.9959 - val_loss: 0.7284 - val_accuracy: 0.7540\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0411 - accuracy: 0.9972 - val_loss: 0.7067 - val_accuracy: 0.7460\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.7857\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8016\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.6855 - val_accuracy: 0.8016\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.7857\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.7857\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.7937\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.7937\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7261 - val_accuracy: 0.8016\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8095\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8095\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8175\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8175\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.8254\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7232 - val_accuracy: 0.8254\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8254\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8254\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.8254\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7313 - val_accuracy: 0.8254\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.8333\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7342 - val_accuracy: 0.8333\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7309 - val_accuracy: 0.8413\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7345 - val_accuracy: 0.8413\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7396 - val_accuracy: 0.8492\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8413\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.8492\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8413\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.8333\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.8492\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 9.4768e-04 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.8492\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 8.9996e-04 - accuracy: 1.0000 - val_loss: 0.7701 - val_accuracy: 0.8413\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 8.5212e-04 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.8492\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 8.0654e-04 - accuracy: 1.0000 - val_loss: 0.7717 - val_accuracy: 0.8492\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 7.6705e-04 - accuracy: 1.0000 - val_loss: 0.7756 - val_accuracy: 0.8492\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 7.2363e-04 - accuracy: 1.0000 - val_loss: 0.7802 - val_accuracy: 0.8492\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 6.8688e-04 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.8492\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 6.5621e-04 - accuracy: 1.0000 - val_loss: 0.7833 - val_accuracy: 0.8492\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 6.2161e-04 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.8492\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 5.8592e-04 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.8492\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 5.5627e-04 - accuracy: 1.0000 - val_loss: 0.7926 - val_accuracy: 0.8413\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 5.2777e-04 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.8413\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 4.9878e-04 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.8413\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 4.7091e-04 - accuracy: 1.0000 - val_loss: 0.8058 - val_accuracy: 0.8413\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 4.4843e-04 - accuracy: 1.0000 - val_loss: 0.8104 - val_accuracy: 0.8413\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 4.2177e-04 - accuracy: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.8413\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 4.0698e-04 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.8413\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 3.8220e-04 - accuracy: 1.0000 - val_loss: 0.8207 - val_accuracy: 0.8413\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 3.6471e-04 - accuracy: 1.0000 - val_loss: 0.8220 - val_accuracy: 0.8413\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 3.4596e-04 - accuracy: 1.0000 - val_loss: 0.8226 - val_accuracy: 0.8413\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 3.2714e-04 - accuracy: 1.0000 - val_loss: 0.8242 - val_accuracy: 0.8413\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 3.1220e-04 - accuracy: 1.0000 - val_loss: 0.8324 - val_accuracy: 0.8413\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.9903e-04 - accuracy: 1.0000 - val_loss: 0.8367 - val_accuracy: 0.8413\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 2.8562e-04 - accuracy: 1.0000 - val_loss: 0.8356 - val_accuracy: 0.8413\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.7313e-04 - accuracy: 1.0000 - val_loss: 0.8374 - val_accuracy: 0.8413\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 2.5878e-04 - accuracy: 1.0000 - val_loss: 0.8446 - val_accuracy: 0.8413\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.4790e-04 - accuracy: 1.0000 - val_loss: 0.8431 - val_accuracy: 0.8413\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.3685e-04 - accuracy: 1.0000 - val_loss: 0.8433 - val_accuracy: 0.8413\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.2672e-04 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.8413\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.1758e-04 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.8413\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0909e-04 - accuracy: 1.0000 - val_loss: 0.8513 - val_accuracy: 0.8413\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.9876e-04 - accuracy: 1.0000 - val_loss: 0.8590 - val_accuracy: 0.8413\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8904e-04 - accuracy: 1.0000 - val_loss: 0.8597 - val_accuracy: 0.8413\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8202e-04 - accuracy: 1.0000 - val_loss: 0.8621 - val_accuracy: 0.8413\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7540e-04 - accuracy: 1.0000 - val_loss: 0.8651 - val_accuracy: 0.8413\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6702e-04 - accuracy: 1.0000 - val_loss: 0.8676 - val_accuracy: 0.8413\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6104e-04 - accuracy: 1.0000 - val_loss: 0.8685 - val_accuracy: 0.8413\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5419e-04 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.8413\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.4905e-04 - accuracy: 1.0000 - val_loss: 0.8828 - val_accuracy: 0.8413\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 1.4071e-04 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.8413\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 2s 110ms/step - loss: 1.3533e-04 - accuracy: 1.0000 - val_loss: 0.8813 - val_accuracy: 0.8413\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 1.3030e-04 - accuracy: 1.0000 - val_loss: 0.8848 - val_accuracy: 0.8413\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 2s 87ms/step - loss: 1.2453e-04 - accuracy: 1.0000 - val_loss: 0.8894 - val_accuracy: 0.8333\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 1.2135e-04 - accuracy: 1.0000 - val_loss: 0.8910 - val_accuracy: 0.8413\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 2s 100ms/step - loss: 1.1611e-04 - accuracy: 1.0000 - val_loss: 0.8965 - val_accuracy: 0.8333\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 1.1206e-04 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.8254\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 2s 96ms/step - loss: 1.0771e-04 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.8333\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 1.0434e-04 - accuracy: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.8254\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 1.0047e-04 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.8254\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 9.7524e-05 - accuracy: 1.0000 - val_loss: 0.9065 - val_accuracy: 0.8254\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 9.4001e-05 - accuracy: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.8254\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 2s 73ms/step - loss: 9.0398e-05 - accuracy: 1.0000 - val_loss: 0.9110 - val_accuracy: 0.8254\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 8.6825e-05 - accuracy: 1.0000 - val_loss: 0.9130 - val_accuracy: 0.8254\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 8.4567e-05 - accuracy: 1.0000 - val_loss: 0.9122 - val_accuracy: 0.8254\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 8.1665e-05 - accuracy: 1.0000 - val_loss: 0.9165 - val_accuracy: 0.8175\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 7.9110e-05 - accuracy: 1.0000 - val_loss: 0.9202 - val_accuracy: 0.8175\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 7.5996e-05 - accuracy: 1.0000 - val_loss: 0.9220 - val_accuracy: 0.8175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "yoeVB0CtjKi1",
        "outputId": "63fcec63-bb91-4a10-92a4-8bd5c29b8934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1= Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(4,4), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "     MaxPool2D(),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "    Conv2D(32,3, activation=\"relu\"),\n",
        "       MaxPool2D(),\n",
        "    Flatten(),\n",
        "    \n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_1.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_1=model_1.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W_njP45joBL",
        "outputId": "297e6ac2-effe-4f53-8f2a-c72b8638d98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 4s 91ms/step - loss: 1.9495 - accuracy: 0.1307 - val_loss: 1.9449 - val_accuracy: 0.1667\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 1.9421 - accuracy: 0.1664 - val_loss: 1.9297 - val_accuracy: 0.1587\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.8101 - accuracy: 0.2572 - val_loss: 1.7561 - val_accuracy: 0.2381\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 1.5041 - accuracy: 0.4099 - val_loss: 1.7118 - val_accuracy: 0.3413\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.3815 - accuracy: 0.4553 - val_loss: 1.5816 - val_accuracy: 0.3175\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.2564 - accuracy: 0.4993 - val_loss: 1.4950 - val_accuracy: 0.3730\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.2121 - accuracy: 0.5392 - val_loss: 1.4316 - val_accuracy: 0.4127\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.1025 - accuracy: 0.5695 - val_loss: 1.2809 - val_accuracy: 0.5079\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.0206 - accuracy: 0.6245 - val_loss: 1.2309 - val_accuracy: 0.5476\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.9569 - accuracy: 0.6547 - val_loss: 1.2120 - val_accuracy: 0.5476\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.8848 - accuracy: 0.6616 - val_loss: 1.1317 - val_accuracy: 0.5952\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.7971 - accuracy: 0.7043 - val_loss: 1.1329 - val_accuracy: 0.5873\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.7798 - accuracy: 0.7084 - val_loss: 1.0454 - val_accuracy: 0.6111\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.7041 - accuracy: 0.7263 - val_loss: 0.9950 - val_accuracy: 0.6667\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.6986 - accuracy: 0.7387 - val_loss: 1.0749 - val_accuracy: 0.5873\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.6224 - accuracy: 0.7758 - val_loss: 0.9602 - val_accuracy: 0.6429\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.6300 - accuracy: 0.7689 - val_loss: 1.0545 - val_accuracy: 0.6508\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.5775 - accuracy: 0.7950 - val_loss: 0.9497 - val_accuracy: 0.6905\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.4754 - accuracy: 0.8226 - val_loss: 0.8546 - val_accuracy: 0.7143\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 0.4302 - accuracy: 0.8528 - val_loss: 0.8370 - val_accuracy: 0.6825\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.3893 - accuracy: 0.8707 - val_loss: 0.8751 - val_accuracy: 0.6984\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.3887 - accuracy: 0.8583 - val_loss: 0.7601 - val_accuracy: 0.7381\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.3002 - accuracy: 0.8927 - val_loss: 0.9124 - val_accuracy: 0.7063\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.2477 - accuracy: 0.9133 - val_loss: 1.0011 - val_accuracy: 0.7143\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.2510 - accuracy: 0.9023 - val_loss: 0.8867 - val_accuracy: 0.7143\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.2313 - accuracy: 0.9285 - val_loss: 0.9933 - val_accuracy: 0.6984\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.1724 - accuracy: 0.9464 - val_loss: 0.8802 - val_accuracy: 0.7540\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.1492 - accuracy: 0.9532 - val_loss: 0.8475 - val_accuracy: 0.7540\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.1374 - accuracy: 0.9532 - val_loss: 0.9399 - val_accuracy: 0.7698\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.1456 - accuracy: 0.9422 - val_loss: 1.0926 - val_accuracy: 0.7222\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.1100 - accuracy: 0.9615 - val_loss: 0.8587 - val_accuracy: 0.7698\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.1005 - accuracy: 0.9670 - val_loss: 0.8880 - val_accuracy: 0.7619\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.0643 - accuracy: 0.9821 - val_loss: 1.0285 - val_accuracy: 0.7619\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.1081 - accuracy: 0.9642 - val_loss: 0.9021 - val_accuracy: 0.7619\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.1362 - accuracy: 0.9546 - val_loss: 0.9820 - val_accuracy: 0.7222\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.0795 - accuracy: 0.9752 - val_loss: 1.0820 - val_accuracy: 0.7778\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0754 - accuracy: 0.9766 - val_loss: 1.0611 - val_accuracy: 0.7540\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.0504 - accuracy: 0.9890 - val_loss: 1.0533 - val_accuracy: 0.7937\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.0198 - accuracy: 0.9986 - val_loss: 0.9782 - val_accuracy: 0.7937\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.0122 - accuracy: 0.9986 - val_loss: 1.1936 - val_accuracy: 0.7698\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.0092 - accuracy: 0.9986 - val_loss: 1.1452 - val_accuracy: 0.7778\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1661 - val_accuracy: 0.7778\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 0.7937\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2160 - val_accuracy: 0.7619\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2492 - val_accuracy: 0.7619\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2700 - val_accuracy: 0.7619\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2821 - val_accuracy: 0.7540\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2919 - val_accuracy: 0.7540\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3153 - val_accuracy: 0.7619\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3187 - val_accuracy: 0.7619\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3252 - val_accuracy: 0.7698\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3446 - val_accuracy: 0.7540\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 9.4776e-04 - accuracy: 1.0000 - val_loss: 1.3526 - val_accuracy: 0.7619\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 8.9673e-04 - accuracy: 1.0000 - val_loss: 1.3709 - val_accuracy: 0.7540\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 8.7703e-04 - accuracy: 1.0000 - val_loss: 1.3691 - val_accuracy: 0.7540\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 7.9909e-04 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.7540\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 7.5474e-04 - accuracy: 1.0000 - val_loss: 1.3896 - val_accuracy: 0.7540\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 7.0950e-04 - accuracy: 1.0000 - val_loss: 1.4065 - val_accuracy: 0.7540\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 6.6793e-04 - accuracy: 1.0000 - val_loss: 1.4108 - val_accuracy: 0.7540\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 6.4176e-04 - accuracy: 1.0000 - val_loss: 1.4172 - val_accuracy: 0.7619\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 6.1220e-04 - accuracy: 1.0000 - val_loss: 1.4290 - val_accuracy: 0.7619\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 5.8612e-04 - accuracy: 1.0000 - val_loss: 1.4371 - val_accuracy: 0.7619\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 5.6085e-04 - accuracy: 1.0000 - val_loss: 1.4425 - val_accuracy: 0.7619\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 5.3398e-04 - accuracy: 1.0000 - val_loss: 1.4596 - val_accuracy: 0.7540\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 5.0673e-04 - accuracy: 1.0000 - val_loss: 1.4518 - val_accuracy: 0.7540\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 4.9215e-04 - accuracy: 1.0000 - val_loss: 1.4650 - val_accuracy: 0.7619\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 4.7230e-04 - accuracy: 1.0000 - val_loss: 1.4722 - val_accuracy: 0.7619\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 4.4793e-04 - accuracy: 1.0000 - val_loss: 1.4750 - val_accuracy: 0.7540\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 4.4051e-04 - accuracy: 1.0000 - val_loss: 1.4861 - val_accuracy: 0.7619\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 4.1910e-04 - accuracy: 1.0000 - val_loss: 1.4876 - val_accuracy: 0.7619\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 3.9811e-04 - accuracy: 1.0000 - val_loss: 1.4936 - val_accuracy: 0.7619\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 3.8612e-04 - accuracy: 1.0000 - val_loss: 1.5037 - val_accuracy: 0.7619\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 3.7296e-04 - accuracy: 1.0000 - val_loss: 1.5088 - val_accuracy: 0.7619\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 3.5800e-04 - accuracy: 1.0000 - val_loss: 1.5127 - val_accuracy: 0.7619\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 3.4811e-04 - accuracy: 1.0000 - val_loss: 1.5175 - val_accuracy: 0.7619\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 3.3477e-04 - accuracy: 1.0000 - val_loss: 1.5286 - val_accuracy: 0.7619\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 3.2427e-04 - accuracy: 1.0000 - val_loss: 1.5344 - val_accuracy: 0.7619\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 3.2044e-04 - accuracy: 1.0000 - val_loss: 1.5361 - val_accuracy: 0.7619\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 3.0513e-04 - accuracy: 1.0000 - val_loss: 1.5424 - val_accuracy: 0.7619\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 2.9425e-04 - accuracy: 1.0000 - val_loss: 1.5509 - val_accuracy: 0.7619\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 2.8599e-04 - accuracy: 1.0000 - val_loss: 1.5599 - val_accuracy: 0.7619\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 2.7560e-04 - accuracy: 1.0000 - val_loss: 1.5566 - val_accuracy: 0.7619\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 2.7039e-04 - accuracy: 1.0000 - val_loss: 1.5630 - val_accuracy: 0.7619\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 2.5880e-04 - accuracy: 1.0000 - val_loss: 1.5720 - val_accuracy: 0.7619\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 2.5126e-04 - accuracy: 1.0000 - val_loss: 1.5790 - val_accuracy: 0.7619\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 2.4235e-04 - accuracy: 1.0000 - val_loss: 1.5795 - val_accuracy: 0.7619\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 2.3628e-04 - accuracy: 1.0000 - val_loss: 1.5868 - val_accuracy: 0.7619\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 2.2746e-04 - accuracy: 1.0000 - val_loss: 1.5896 - val_accuracy: 0.7619\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 1s 45ms/step - loss: 2.2268e-04 - accuracy: 1.0000 - val_loss: 1.5967 - val_accuracy: 0.7619\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 2.1557e-04 - accuracy: 1.0000 - val_loss: 1.6023 - val_accuracy: 0.7619\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 2.0838e-04 - accuracy: 1.0000 - val_loss: 1.6074 - val_accuracy: 0.7619\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 2.0323e-04 - accuracy: 1.0000 - val_loss: 1.6111 - val_accuracy: 0.7619\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 2.0134e-04 - accuracy: 1.0000 - val_loss: 1.6172 - val_accuracy: 0.7619\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.9315e-04 - accuracy: 1.0000 - val_loss: 1.6176 - val_accuracy: 0.7619\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.8591e-04 - accuracy: 1.0000 - val_loss: 1.6245 - val_accuracy: 0.7619\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.8192e-04 - accuracy: 1.0000 - val_loss: 1.6294 - val_accuracy: 0.7619\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.7624e-04 - accuracy: 1.0000 - val_loss: 1.6363 - val_accuracy: 0.7619\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 1.7167e-04 - accuracy: 1.0000 - val_loss: 1.6339 - val_accuracy: 0.7619\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 1.6741e-04 - accuracy: 1.0000 - val_loss: 1.6429 - val_accuracy: 0.7619\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 1.6286e-04 - accuracy: 1.0000 - val_loss: 1.6504 - val_accuracy: 0.7619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2= Sequential([\n",
        "    Conv2D(filters=128, kernel_size=(5,5), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    BatchNormalization(name='batchnorm_1'),\n",
        "    Conv2D(128,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(128,3, activation=\"relu\"),\n",
        "    Conv2D(128,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(128,3, activation=\"relu\"),\n",
        "    Conv2D(128,3, activation=\"relu\"),\n",
        "    BatchNormalization(name='batchnorm_2'),\n",
        "    Conv2D(128,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(100, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_2.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_2=model_2.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EImK-JmWkY-7",
        "outputId": "de4e4af2-7d5e-44f5-db57-062bca7ae266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 7s 210ms/step - loss: 2.0282 - accuracy: 0.2187 - val_loss: 2.0069 - val_accuracy: 0.1508\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 1.7583 - accuracy: 0.3315 - val_loss: 1.9846 - val_accuracy: 0.1429\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 2s 96ms/step - loss: 1.4618 - accuracy: 0.4360 - val_loss: 2.1811 - val_accuracy: 0.1429\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 1.2231 - accuracy: 0.5296 - val_loss: 2.2480 - val_accuracy: 0.1429\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 2s 98ms/step - loss: 1.0794 - accuracy: 0.5750 - val_loss: 2.2128 - val_accuracy: 0.1429\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.9627 - accuracy: 0.6355 - val_loss: 2.9316 - val_accuracy: 0.1429\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.8111 - accuracy: 0.7084 - val_loss: 2.6001 - val_accuracy: 0.1984\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.7509 - accuracy: 0.7098 - val_loss: 2.4199 - val_accuracy: 0.1984\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.6821 - accuracy: 0.7579 - val_loss: 2.5255 - val_accuracy: 0.2222\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5664 - accuracy: 0.7895 - val_loss: 3.0557 - val_accuracy: 0.1508\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5977 - accuracy: 0.7772 - val_loss: 3.1344 - val_accuracy: 0.1429\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.4753 - accuracy: 0.8253 - val_loss: 3.7647 - val_accuracy: 0.1508\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.3578 - accuracy: 0.8693 - val_loss: 4.0758 - val_accuracy: 0.2460\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.3280 - accuracy: 0.8858 - val_loss: 3.2306 - val_accuracy: 0.2143\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.2465 - accuracy: 0.9257 - val_loss: 3.8098 - val_accuracy: 0.1667\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.2284 - accuracy: 0.9202 - val_loss: 3.0298 - val_accuracy: 0.2857\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.2112 - accuracy: 0.9271 - val_loss: 3.7298 - val_accuracy: 0.2222\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 0.2959 - accuracy: 0.9010 - val_loss: 1.9153 - val_accuracy: 0.4127\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.2226 - accuracy: 0.9285 - val_loss: 2.6584 - val_accuracy: 0.3016\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.1874 - accuracy: 0.9230 - val_loss: 1.9771 - val_accuracy: 0.4206\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.1391 - accuracy: 0.9546 - val_loss: 1.3501 - val_accuracy: 0.5476\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0763 - accuracy: 0.9917 - val_loss: 1.8730 - val_accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.0871 - accuracy: 0.9766 - val_loss: 1.6151 - val_accuracy: 0.5476\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.0534 - accuracy: 0.9917 - val_loss: 1.5700 - val_accuracy: 0.6032\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.0469 - accuracy: 0.9890 - val_loss: 1.7535 - val_accuracy: 0.5714\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0355 - accuracy: 0.9972 - val_loss: 1.0478 - val_accuracy: 0.7063\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0205 - accuracy: 0.9972 - val_loss: 1.2240 - val_accuracy: 0.6825\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.1056 - val_accuracy: 0.7063\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0798 - val_accuracy: 0.7063\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0068 - val_accuracy: 0.7460\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0821 - val_accuracy: 0.7460\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0092 - accuracy: 0.9959 - val_loss: 1.0144 - val_accuracy: 0.7460\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9515 - val_accuracy: 0.8016\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8957 - val_accuracy: 0.7937\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8768 - val_accuracy: 0.8175\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8906 - val_accuracy: 0.8175\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8531 - val_accuracy: 0.8254\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8672 - val_accuracy: 0.8254\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8610 - val_accuracy: 0.8254\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8641 - val_accuracy: 0.8254\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8663 - val_accuracy: 0.8175\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8637 - val_accuracy: 0.8333\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8597 - val_accuracy: 0.8175\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.8254\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 2s 88ms/step - loss: 9.7339e-04 - accuracy: 1.0000 - val_loss: 0.8772 - val_accuracy: 0.8333\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 9.2700e-04 - accuracy: 1.0000 - val_loss: 0.8669 - val_accuracy: 0.8254\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 9.2277e-04 - accuracy: 1.0000 - val_loss: 0.8759 - val_accuracy: 0.8333\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 2s 99ms/step - loss: 8.6769e-04 - accuracy: 1.0000 - val_loss: 0.8616 - val_accuracy: 0.8254\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 3s 120ms/step - loss: 8.3742e-04 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.8254\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 7.8583e-04 - accuracy: 1.0000 - val_loss: 0.8655 - val_accuracy: 0.8175\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 2s 97ms/step - loss: 7.4496e-04 - accuracy: 1.0000 - val_loss: 0.8641 - val_accuracy: 0.8095\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 2s 95ms/step - loss: 7.1537e-04 - accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.8175\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 6.8356e-04 - accuracy: 1.0000 - val_loss: 0.8700 - val_accuracy: 0.8175\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 2s 97ms/step - loss: 6.4738e-04 - accuracy: 1.0000 - val_loss: 0.8743 - val_accuracy: 0.8175\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 2s 103ms/step - loss: 6.2465e-04 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.8175\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 6.0141e-04 - accuracy: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.8175\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 5.5524e-04 - accuracy: 1.0000 - val_loss: 0.8843 - val_accuracy: 0.8175\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 5.5040e-04 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.8254\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 5.0487e-04 - accuracy: 1.0000 - val_loss: 0.8845 - val_accuracy: 0.8175\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 5.0487e-04 - accuracy: 1.0000 - val_loss: 0.8829 - val_accuracy: 0.8175\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 4.7519e-04 - accuracy: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.8175\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 4.6551e-04 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.8175\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 4.3672e-04 - accuracy: 1.0000 - val_loss: 0.8821 - val_accuracy: 0.8175\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 4.3062e-04 - accuracy: 1.0000 - val_loss: 0.8873 - val_accuracy: 0.8175\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 4.2384e-04 - accuracy: 1.0000 - val_loss: 0.8904 - val_accuracy: 0.8175\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 3.9331e-04 - accuracy: 1.0000 - val_loss: 0.8957 - val_accuracy: 0.8095\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 4.0080e-04 - accuracy: 1.0000 - val_loss: 0.8896 - val_accuracy: 0.8175\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 3.7303e-04 - accuracy: 1.0000 - val_loss: 0.8955 - val_accuracy: 0.8095\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 3.4951e-04 - accuracy: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.8175\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 3.4690e-04 - accuracy: 1.0000 - val_loss: 0.8945 - val_accuracy: 0.8175\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 3.3391e-04 - accuracy: 1.0000 - val_loss: 0.8952 - val_accuracy: 0.8254\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 3.2653e-04 - accuracy: 1.0000 - val_loss: 0.8981 - val_accuracy: 0.8254\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 3.0997e-04 - accuracy: 1.0000 - val_loss: 0.8961 - val_accuracy: 0.8254\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 2.9609e-04 - accuracy: 1.0000 - val_loss: 0.8853 - val_accuracy: 0.8175\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 2.9786e-04 - accuracy: 1.0000 - val_loss: 0.9061 - val_accuracy: 0.8254\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 2.8798e-04 - accuracy: 1.0000 - val_loss: 0.9106 - val_accuracy: 0.8254\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 2.7157e-04 - accuracy: 1.0000 - val_loss: 0.9165 - val_accuracy: 0.8095\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 2.5290e-04 - accuracy: 1.0000 - val_loss: 0.9141 - val_accuracy: 0.8254\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 2.5002e-04 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.8175\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 2s 97ms/step - loss: 2.5101e-04 - accuracy: 1.0000 - val_loss: 0.9169 - val_accuracy: 0.8095\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 3s 117ms/step - loss: 2.4182e-04 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.8175\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 2.2888e-04 - accuracy: 1.0000 - val_loss: 0.9191 - val_accuracy: 0.8254\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 2.3191e-04 - accuracy: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.8175\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 2.2325e-04 - accuracy: 1.0000 - val_loss: 0.9244 - val_accuracy: 0.8175\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 2.0910e-04 - accuracy: 1.0000 - val_loss: 0.9267 - val_accuracy: 0.8095\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 2.1120e-04 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.8095\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 2.0600e-04 - accuracy: 1.0000 - val_loss: 0.9270 - val_accuracy: 0.8175\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 1.9792e-04 - accuracy: 1.0000 - val_loss: 0.9296 - val_accuracy: 0.8175\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 1.8467e-04 - accuracy: 1.0000 - val_loss: 0.9282 - val_accuracy: 0.8254\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 1.7631e-04 - accuracy: 1.0000 - val_loss: 0.9331 - val_accuracy: 0.8254\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 1.7337e-04 - accuracy: 1.0000 - val_loss: 0.9369 - val_accuracy: 0.8175\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 1.7465e-04 - accuracy: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.8175\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 1.7189e-04 - accuracy: 1.0000 - val_loss: 0.9312 - val_accuracy: 0.8175\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 2s 86ms/step - loss: 1.6440e-04 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.8175\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 2s 86ms/step - loss: 1.5940e-04 - accuracy: 1.0000 - val_loss: 0.9370 - val_accuracy: 0.8254\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 1.5443e-04 - accuracy: 1.0000 - val_loss: 0.9409 - val_accuracy: 0.8175\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 1.5002e-04 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.8095\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 1.4398e-04 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.8254\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 2s 97ms/step - loss: 1.4228e-04 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.8175\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 2s 103ms/step - loss: 1.3406e-04 - accuracy: 1.0000 - val_loss: 0.9429 - val_accuracy: 0.8175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2= Sequential([\n",
        "    Conv2D(filters=64, kernel_size=(5,5), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(40, activation=\"relu\"),\n",
        "    Dense(40, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_2.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_2=model_2.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmeK2d1XlzZ_",
        "outputId": "20e12652-5e55-493e-fc3e-97e52cc1dea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 3s 92ms/step - loss: 1.9484 - accuracy: 0.1403 - val_loss: 1.9438 - val_accuracy: 0.1429\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 1.9365 - accuracy: 0.1816 - val_loss: 1.8941 - val_accuracy: 0.2460\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 1.7666 - accuracy: 0.2682 - val_loss: 1.6029 - val_accuracy: 0.3413\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.3935 - accuracy: 0.4828 - val_loss: 1.3865 - val_accuracy: 0.5556\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.1213 - accuracy: 0.5805 - val_loss: 1.2398 - val_accuracy: 0.5873\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.0022 - accuracy: 0.6575 - val_loss: 1.0758 - val_accuracy: 0.5952\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.8433 - accuracy: 0.6933 - val_loss: 1.0181 - val_accuracy: 0.6429\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.6384 - accuracy: 0.7730 - val_loss: 1.1543 - val_accuracy: 0.6111\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.5732 - accuracy: 0.8006 - val_loss: 0.9063 - val_accuracy: 0.6746\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4655 - accuracy: 0.8404 - val_loss: 0.9732 - val_accuracy: 0.6746\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4520 - accuracy: 0.8473 - val_loss: 0.9804 - val_accuracy: 0.6746\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.3178 - accuracy: 0.8927 - val_loss: 0.8615 - val_accuracy: 0.7698\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.2447 - accuracy: 0.9147 - val_loss: 0.9779 - val_accuracy: 0.7540\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.2138 - accuracy: 0.9354 - val_loss: 0.8145 - val_accuracy: 0.8175\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.1659 - accuracy: 0.9381 - val_loss: 1.1622 - val_accuracy: 0.7302\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.1542 - accuracy: 0.9560 - val_loss: 1.1358 - val_accuracy: 0.7778\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.1324 - accuracy: 0.9587 - val_loss: 1.1845 - val_accuracy: 0.7460\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.1618 - accuracy: 0.9395 - val_loss: 1.0320 - val_accuracy: 0.8016\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.0994 - accuracy: 0.9587 - val_loss: 0.9400 - val_accuracy: 0.7937\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.0385 - accuracy: 0.9917 - val_loss: 1.2213 - val_accuracy: 0.7698\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.0266 - accuracy: 0.9945 - val_loss: 1.3918 - val_accuracy: 0.7857\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.0232 - accuracy: 0.9945 - val_loss: 1.3177 - val_accuracy: 0.8175\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.3172 - val_accuracy: 0.8095\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 2s 87ms/step - loss: 0.0154 - accuracy: 0.9917 - val_loss: 1.4156 - val_accuracy: 0.8254\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 1.4586 - val_accuracy: 0.8095\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5378 - val_accuracy: 0.8016\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 8.4751e-04 - accuracy: 1.0000 - val_loss: 1.6015 - val_accuracy: 0.8254\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 5.2542e-04 - accuracy: 1.0000 - val_loss: 1.6144 - val_accuracy: 0.8333\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 3.9162e-04 - accuracy: 1.0000 - val_loss: 1.6435 - val_accuracy: 0.8413\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 3.3210e-04 - accuracy: 1.0000 - val_loss: 1.6657 - val_accuracy: 0.8333\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.9043e-04 - accuracy: 1.0000 - val_loss: 1.6848 - val_accuracy: 0.8333\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 2.5822e-04 - accuracy: 1.0000 - val_loss: 1.7015 - val_accuracy: 0.8333\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.3108e-04 - accuracy: 1.0000 - val_loss: 1.7193 - val_accuracy: 0.8333\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 2.0944e-04 - accuracy: 1.0000 - val_loss: 1.7356 - val_accuracy: 0.8333\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.9135e-04 - accuracy: 1.0000 - val_loss: 1.7520 - val_accuracy: 0.8333\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.7675e-04 - accuracy: 1.0000 - val_loss: 1.7653 - val_accuracy: 0.8333\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.6347e-04 - accuracy: 1.0000 - val_loss: 1.7772 - val_accuracy: 0.8333\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5158e-04 - accuracy: 1.0000 - val_loss: 1.7914 - val_accuracy: 0.8333\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.3909e-04 - accuracy: 1.0000 - val_loss: 1.8036 - val_accuracy: 0.8333\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.3212e-04 - accuracy: 1.0000 - val_loss: 1.8174 - val_accuracy: 0.8333\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.2202e-04 - accuracy: 1.0000 - val_loss: 1.8311 - val_accuracy: 0.8333\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.1404e-04 - accuracy: 1.0000 - val_loss: 1.8393 - val_accuracy: 0.8333\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.0806e-04 - accuracy: 1.0000 - val_loss: 1.8477 - val_accuracy: 0.8333\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 1.0163e-04 - accuracy: 1.0000 - val_loss: 1.8608 - val_accuracy: 0.8333\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 9.5688e-05 - accuracy: 1.0000 - val_loss: 1.8703 - val_accuracy: 0.8333\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 9.1602e-05 - accuracy: 1.0000 - val_loss: 1.8799 - val_accuracy: 0.8333\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 8.7020e-05 - accuracy: 1.0000 - val_loss: 1.8897 - val_accuracy: 0.8333\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 8.2848e-05 - accuracy: 1.0000 - val_loss: 1.8995 - val_accuracy: 0.8333\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 7.8306e-05 - accuracy: 1.0000 - val_loss: 1.9042 - val_accuracy: 0.8333\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 7.4706e-05 - accuracy: 1.0000 - val_loss: 1.9148 - val_accuracy: 0.8333\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 7.1517e-05 - accuracy: 1.0000 - val_loss: 1.9230 - val_accuracy: 0.8333\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 6.8586e-05 - accuracy: 1.0000 - val_loss: 1.9283 - val_accuracy: 0.8333\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 6.6051e-05 - accuracy: 1.0000 - val_loss: 1.9395 - val_accuracy: 0.8333\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 6.2563e-05 - accuracy: 1.0000 - val_loss: 1.9453 - val_accuracy: 0.8333\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 5.9744e-05 - accuracy: 1.0000 - val_loss: 1.9535 - val_accuracy: 0.8333\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 2s 69ms/step - loss: 5.7718e-05 - accuracy: 1.0000 - val_loss: 1.9611 - val_accuracy: 0.8333\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 5.5708e-05 - accuracy: 1.0000 - val_loss: 1.9690 - val_accuracy: 0.8333\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 5.3041e-05 - accuracy: 1.0000 - val_loss: 1.9764 - val_accuracy: 0.8333\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 2s 68ms/step - loss: 5.1509e-05 - accuracy: 1.0000 - val_loss: 1.9821 - val_accuracy: 0.8333\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 4.9188e-05 - accuracy: 1.0000 - val_loss: 1.9895 - val_accuracy: 0.8333\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 4.7243e-05 - accuracy: 1.0000 - val_loss: 1.9946 - val_accuracy: 0.8333\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 4.5612e-05 - accuracy: 1.0000 - val_loss: 2.0022 - val_accuracy: 0.8333\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 4.3827e-05 - accuracy: 1.0000 - val_loss: 2.0082 - val_accuracy: 0.8333\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 4.2384e-05 - accuracy: 1.0000 - val_loss: 2.0144 - val_accuracy: 0.8333\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 4.0936e-05 - accuracy: 1.0000 - val_loss: 2.0229 - val_accuracy: 0.8333\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 3.9786e-05 - accuracy: 1.0000 - val_loss: 2.0281 - val_accuracy: 0.8333\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 3.8531e-05 - accuracy: 1.0000 - val_loss: 2.0339 - val_accuracy: 0.8333\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 3.7213e-05 - accuracy: 1.0000 - val_loss: 2.0400 - val_accuracy: 0.8333\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 3.5921e-05 - accuracy: 1.0000 - val_loss: 2.0481 - val_accuracy: 0.8333\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 3.4625e-05 - accuracy: 1.0000 - val_loss: 2.0527 - val_accuracy: 0.8333\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 3.3491e-05 - accuracy: 1.0000 - val_loss: 2.0585 - val_accuracy: 0.8333\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 3.2440e-05 - accuracy: 1.0000 - val_loss: 2.0634 - val_accuracy: 0.8333\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 2s 65ms/step - loss: 3.1521e-05 - accuracy: 1.0000 - val_loss: 2.0710 - val_accuracy: 0.8333\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 2s 63ms/step - loss: 3.0542e-05 - accuracy: 1.0000 - val_loss: 2.0764 - val_accuracy: 0.8333\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 1s 63ms/step - loss: 2.9718e-05 - accuracy: 1.0000 - val_loss: 2.0813 - val_accuracy: 0.8333\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 2.8895e-05 - accuracy: 1.0000 - val_loss: 2.0849 - val_accuracy: 0.8333\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 2s 70ms/step - loss: 2.8081e-05 - accuracy: 1.0000 - val_loss: 2.0925 - val_accuracy: 0.8333\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 2s 66ms/step - loss: 2.7177e-05 - accuracy: 1.0000 - val_loss: 2.0962 - val_accuracy: 0.8333\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 2s 87ms/step - loss: 2.6407e-05 - accuracy: 1.0000 - val_loss: 2.1035 - val_accuracy: 0.8333\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 2s 72ms/step - loss: 2.5763e-05 - accuracy: 1.0000 - val_loss: 2.1083 - val_accuracy: 0.8333\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 2.4962e-05 - accuracy: 1.0000 - val_loss: 2.1123 - val_accuracy: 0.8333\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 2s 74ms/step - loss: 2.4145e-05 - accuracy: 1.0000 - val_loss: 2.1167 - val_accuracy: 0.8333\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 2.3509e-05 - accuracy: 1.0000 - val_loss: 2.1230 - val_accuracy: 0.8333\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 3s 119ms/step - loss: 2.2964e-05 - accuracy: 1.0000 - val_loss: 2.1290 - val_accuracy: 0.8333\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 3s 106ms/step - loss: 2.2367e-05 - accuracy: 1.0000 - val_loss: 2.1326 - val_accuracy: 0.8333\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 3s 116ms/step - loss: 2.1634e-05 - accuracy: 1.0000 - val_loss: 2.1386 - val_accuracy: 0.8333\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 2s 88ms/step - loss: 2.1205e-05 - accuracy: 1.0000 - val_loss: 2.1429 - val_accuracy: 0.8333\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 2.0552e-05 - accuracy: 1.0000 - val_loss: 2.1478 - val_accuracy: 0.8333\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 2.0086e-05 - accuracy: 1.0000 - val_loss: 2.1513 - val_accuracy: 0.8333\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 1.9516e-05 - accuracy: 1.0000 - val_loss: 2.1562 - val_accuracy: 0.8333\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 1.9057e-05 - accuracy: 1.0000 - val_loss: 2.1601 - val_accuracy: 0.8333\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 1.8649e-05 - accuracy: 1.0000 - val_loss: 2.1649 - val_accuracy: 0.8333\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 2s 71ms/step - loss: 1.8134e-05 - accuracy: 1.0000 - val_loss: 2.1695 - val_accuracy: 0.8333\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 1.7692e-05 - accuracy: 1.0000 - val_loss: 2.1741 - val_accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 1.7263e-05 - accuracy: 1.0000 - val_loss: 2.1779 - val_accuracy: 0.8333\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 1.6887e-05 - accuracy: 1.0000 - val_loss: 2.1820 - val_accuracy: 0.8333\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.6438e-05 - accuracy: 1.0000 - val_loss: 2.1862 - val_accuracy: 0.8333\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.6076e-05 - accuracy: 1.0000 - val_loss: 2.1912 - val_accuracy: 0.8333\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 1.5711e-05 - accuracy: 1.0000 - val_loss: 2.1942 - val_accuracy: 0.8333\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 1.5328e-05 - accuracy: 1.0000 - val_loss: 2.1986 - val_accuracy: 0.8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### modeller maksimum 3 tane maxpool içermeli"
      ],
      "metadata": {
        "id": "rpae4wVVp4yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3= Sequential([\n",
        "    Conv2D(filters=64, kernel_size=(5,5), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    Conv2D(64,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(128,3, activation=\"relu\"),\n",
        "    Conv2D(128,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_3.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_3=model_3.fit(\n",
        "    train_data,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzM1j9f2nw9y",
        "outputId": "9f443f43-6554-4ec9-e8c9-4e831fd24665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 2s 63ms/step - loss: 1.9558 - accuracy: 0.1651 - val_loss: 1.9326 - val_accuracy: 0.1746\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.7592 - accuracy: 0.3260 - val_loss: 1.4714 - val_accuracy: 0.4286\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.2187 - accuracy: 0.5213 - val_loss: 1.2179 - val_accuracy: 0.5476\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.9954 - accuracy: 0.6547 - val_loss: 1.1785 - val_accuracy: 0.5556\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.8519 - accuracy: 0.6589 - val_loss: 1.1159 - val_accuracy: 0.5873\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.6387 - accuracy: 0.7593 - val_loss: 0.9530 - val_accuracy: 0.6825\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4986 - accuracy: 0.8157 - val_loss: 1.0675 - val_accuracy: 0.6825\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4138 - accuracy: 0.8446 - val_loss: 0.8293 - val_accuracy: 0.7698\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.2517 - accuracy: 0.9092 - val_loss: 0.8447 - val_accuracy: 0.7540\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.1925 - accuracy: 0.9354 - val_loss: 1.1247 - val_accuracy: 0.7143\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.1496 - accuracy: 0.9395 - val_loss: 0.9011 - val_accuracy: 0.7619\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.1170 - accuracy: 0.9656 - val_loss: 0.9515 - val_accuracy: 0.8016\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.1391 - accuracy: 0.9491 - val_loss: 0.8683 - val_accuracy: 0.7857\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.0885 - accuracy: 0.9656 - val_loss: 0.9089 - val_accuracy: 0.8175\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.0515 - accuracy: 0.9739 - val_loss: 1.0875 - val_accuracy: 0.8095\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.0388 - accuracy: 0.9876 - val_loss: 1.1331 - val_accuracy: 0.7460\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.0790 - accuracy: 0.9821 - val_loss: 0.7412 - val_accuracy: 0.8254\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.0629 - accuracy: 0.9794 - val_loss: 0.9675 - val_accuracy: 0.8095\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.0508 - accuracy: 0.9849 - val_loss: 1.4873 - val_accuracy: 0.7619\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.0398 - accuracy: 0.9821 - val_loss: 1.0819 - val_accuracy: 0.8016\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.0215 - accuracy: 0.9904 - val_loss: 1.1870 - val_accuracy: 0.8175\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 59ms/step - loss: 0.0113 - accuracy: 0.9945 - val_loss: 1.3259 - val_accuracy: 0.7937\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 1.4565 - val_accuracy: 0.8175\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 1.2963 - val_accuracy: 0.8095\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2982 - val_accuracy: 0.8016\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 4.4263e-04 - accuracy: 1.0000 - val_loss: 1.2971 - val_accuracy: 0.8254\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.1729e-04 - accuracy: 1.0000 - val_loss: 1.2922 - val_accuracy: 0.8413\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 7.7380e-05 - accuracy: 1.0000 - val_loss: 1.3123 - val_accuracy: 0.8413\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 6.4211e-05 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.8413\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 5.5352e-05 - accuracy: 1.0000 - val_loss: 1.3452 - val_accuracy: 0.8413\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 4.9436e-05 - accuracy: 1.0000 - val_loss: 1.3577 - val_accuracy: 0.8413\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 4.4951e-05 - accuracy: 1.0000 - val_loss: 1.3702 - val_accuracy: 0.8413\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 4.0981e-05 - accuracy: 1.0000 - val_loss: 1.3801 - val_accuracy: 0.8413\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 3.7815e-05 - accuracy: 1.0000 - val_loss: 1.3893 - val_accuracy: 0.8413\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 3.5123e-05 - accuracy: 1.0000 - val_loss: 1.3978 - val_accuracy: 0.8413\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 3.2596e-05 - accuracy: 1.0000 - val_loss: 1.4057 - val_accuracy: 0.8413\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 3.0504e-05 - accuracy: 1.0000 - val_loss: 1.4132 - val_accuracy: 0.8413\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 2.8620e-05 - accuracy: 1.0000 - val_loss: 1.4208 - val_accuracy: 0.8413\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 2.6970e-05 - accuracy: 1.0000 - val_loss: 1.4276 - val_accuracy: 0.8413\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 2.5425e-05 - accuracy: 1.0000 - val_loss: 1.4347 - val_accuracy: 0.8413\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 2.4055e-05 - accuracy: 1.0000 - val_loss: 1.4413 - val_accuracy: 0.8413\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 2.2842e-05 - accuracy: 1.0000 - val_loss: 1.4473 - val_accuracy: 0.8413\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 2.1714e-05 - accuracy: 1.0000 - val_loss: 1.4535 - val_accuracy: 0.8413\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 2.0707e-05 - accuracy: 1.0000 - val_loss: 1.4600 - val_accuracy: 0.8413\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.9651e-05 - accuracy: 1.0000 - val_loss: 1.4646 - val_accuracy: 0.8413\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.8761e-05 - accuracy: 1.0000 - val_loss: 1.4706 - val_accuracy: 0.8413\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.7924e-05 - accuracy: 1.0000 - val_loss: 1.4759 - val_accuracy: 0.8413\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 1.7157e-05 - accuracy: 1.0000 - val_loss: 1.4809 - val_accuracy: 0.8413\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 1.6394e-05 - accuracy: 1.0000 - val_loss: 1.4863 - val_accuracy: 0.8413\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 1.5740e-05 - accuracy: 1.0000 - val_loss: 1.4912 - val_accuracy: 0.8413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4= Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    BatchNormalization(name='batchnorm_1'),\n",
        "    Conv2D(128,3, activation=\"relu\"),\n",
        "    Conv2D(256,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(256,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation=\"relu\"),\n",
        "    Dense(512, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_4.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_4=model_4.fit(\n",
        "    train_data,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdJFVLraqyy7",
        "outputId": "f6e756be-cc99-481b-804b-3eeb1d95a397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 5s 164ms/step - loss: 2.8414 - accuracy: 0.1747 - val_loss: 1.9458 - val_accuracy: 0.1429\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 3s 133ms/step - loss: 1.6716 - accuracy: 0.3508 - val_loss: 1.9287 - val_accuracy: 0.3095\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 1.3350 - accuracy: 0.4869 - val_loss: 1.8905 - val_accuracy: 0.3889\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 1.0285 - accuracy: 0.6162 - val_loss: 1.8478 - val_accuracy: 0.3889\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.8844 - accuracy: 0.6781 - val_loss: 1.7374 - val_accuracy: 0.5238\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.6898 - accuracy: 0.7483 - val_loss: 1.5633 - val_accuracy: 0.6746\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.6090 - accuracy: 0.7703 - val_loss: 1.5369 - val_accuracy: 0.6984\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.5501 - accuracy: 0.7992 - val_loss: 1.5421 - val_accuracy: 0.6746\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.4250 - accuracy: 0.8418 - val_loss: 1.3512 - val_accuracy: 0.6984\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.3776 - accuracy: 0.8693 - val_loss: 1.2215 - val_accuracy: 0.7302\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.2645 - accuracy: 0.8982 - val_loss: 1.0941 - val_accuracy: 0.6429\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.2295 - accuracy: 0.9257 - val_loss: 1.0000 - val_accuracy: 0.7143\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.2418 - accuracy: 0.9092 - val_loss: 0.9507 - val_accuracy: 0.7619\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.2039 - accuracy: 0.9230 - val_loss: 0.8975 - val_accuracy: 0.7063\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.2593 - accuracy: 0.9010 - val_loss: 0.8913 - val_accuracy: 0.7222\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.2080 - accuracy: 0.9257 - val_loss: 0.9253 - val_accuracy: 0.7460\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.1344 - accuracy: 0.9546 - val_loss: 0.8184 - val_accuracy: 0.7619\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.1082 - accuracy: 0.9601 - val_loss: 0.9072 - val_accuracy: 0.6905\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 3s 121ms/step - loss: 0.1029 - accuracy: 0.9656 - val_loss: 0.8050 - val_accuracy: 0.7619\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.1011 - accuracy: 0.9656 - val_loss: 0.8420 - val_accuracy: 0.7540\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.0491 - accuracy: 0.9794 - val_loss: 0.9310 - val_accuracy: 0.7302\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.0635 - accuracy: 0.9780 - val_loss: 0.9562 - val_accuracy: 0.7619\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.0805 - accuracy: 0.9766 - val_loss: 1.0135 - val_accuracy: 0.7698\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.0777 - accuracy: 0.9697 - val_loss: 1.1319 - val_accuracy: 0.7540\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.0637 - accuracy: 0.9766 - val_loss: 1.5278 - val_accuracy: 0.7302\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.0705 - accuracy: 0.9766 - val_loss: 1.1401 - val_accuracy: 0.7937\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 3s 124ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 1.2907 - val_accuracy: 0.7937\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.0248 - accuracy: 0.9890 - val_loss: 1.3984 - val_accuracy: 0.7857\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.0615 - accuracy: 0.9849 - val_loss: 1.5317 - val_accuracy: 0.8016\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 3s 121ms/step - loss: 0.0297 - accuracy: 0.9876 - val_loss: 1.4594 - val_accuracy: 0.8095\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.0173 - accuracy: 0.9931 - val_loss: 1.8249 - val_accuracy: 0.7302\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.0106 - accuracy: 0.9945 - val_loss: 1.8677 - val_accuracy: 0.7857\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 3s 121ms/step - loss: 0.0229 - accuracy: 0.9917 - val_loss: 1.8814 - val_accuracy: 0.7063\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 3s 121ms/step - loss: 0.0838 - accuracy: 0.9752 - val_loss: 1.5305 - val_accuracy: 0.7222\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.1306 - accuracy: 0.9560 - val_loss: 1.3867 - val_accuracy: 0.7143\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.0318 - accuracy: 0.9876 - val_loss: 1.7042 - val_accuracy: 0.7937\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.0244 - accuracy: 0.9972 - val_loss: 1.5724 - val_accuracy: 0.7857\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.9400 - val_accuracy: 0.8095\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 3s 121ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9362 - val_accuracy: 0.8175\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 6.0307e-04 - accuracy: 1.0000 - val_loss: 2.0679 - val_accuracy: 0.8175\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 4.7716e-04 - accuracy: 1.0000 - val_loss: 2.1133 - val_accuracy: 0.8095\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 1.3348e-04 - accuracy: 1.0000 - val_loss: 2.0446 - val_accuracy: 0.8095\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 1.2034e-04 - accuracy: 1.0000 - val_loss: 2.0744 - val_accuracy: 0.8095\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 9.5957e-05 - accuracy: 1.0000 - val_loss: 2.1123 - val_accuracy: 0.8175\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 8.0798e-05 - accuracy: 1.0000 - val_loss: 2.1422 - val_accuracy: 0.8175\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 7.2514e-05 - accuracy: 1.0000 - val_loss: 2.1648 - val_accuracy: 0.8175\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 6.5716e-05 - accuracy: 1.0000 - val_loss: 2.1852 - val_accuracy: 0.8095\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 6.0118e-05 - accuracy: 1.0000 - val_loss: 2.2064 - val_accuracy: 0.8175\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 3s 121ms/step - loss: 5.4848e-05 - accuracy: 1.0000 - val_loss: 2.2246 - val_accuracy: 0.8254\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 3s 125ms/step - loss: 4.9825e-05 - accuracy: 1.0000 - val_loss: 2.2385 - val_accuracy: 0.8175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref= zipfile.ZipFile(\"full_datas.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "V46M4RvrsAxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data_dir=\"full_datas/\"\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "IMAGE_SHAPE= 64\n",
        "#Rescale\n",
        "datagen= ImageDataGenerator(validation_split=0.2 ,rescale=1/255.)\n",
        "\n",
        "#load data from directories\n",
        "\n",
        "train_data = datagen.flow_from_directory(Data_dir,\n",
        "                                                 target_size=(IMG_size,IMG_size),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                               color_mode= \"grayscale\",\n",
        "                                               subset='training')\n",
        "\n",
        "test_data = datagen.flow_from_directory(Data_dir,\n",
        "                                                 target_size=(IMG_size,IMG_size),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                             color_mode= \"grayscale\",\n",
        "                                             subset='validation')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jcN6zPE8zwh",
        "outputId": "be28eb68-3c55-4641-b44c-e62c9586ed20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1263 images belonging to 7 classes.\n",
            "Found 312 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_14= Sequential([\n",
        "    Conv2D(filters=20, kernel_size=(5,5), activation=\"relu\",input_shape=(IMG_size,IMG_size,1)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(20,2, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(40,2, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(80,3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1000, activation=\"relu\"),\n",
        "    Dense(2000, activation=\"relu\"),\n",
        "    Dense(7, activation=\"softmax\")\n",
        "])\n",
        "#Compile the model\n",
        "\n",
        "model_14.compile(loss= \"categorical_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"],\n",
        "                )\n",
        "\n",
        "#fit the model\n",
        "history_14=model_14.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps= len(test_data)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWS4zXmA-Wyb",
        "outputId": "3ab5df72-62b6-4022-d091-1c4f76a89bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 10s 220ms/step - loss: 1.9487 - accuracy: 0.1409 - val_loss: 1.9434 - val_accuracy: 0.1506\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 6s 146ms/step - loss: 1.9445 - accuracy: 0.1386 - val_loss: 1.9418 - val_accuracy: 0.1571\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 1.9430 - accuracy: 0.1568 - val_loss: 1.9403 - val_accuracy: 0.1571\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 1.8612 - accuracy: 0.2067 - val_loss: 1.8756 - val_accuracy: 0.2436\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 1.6611 - accuracy: 0.2882 - val_loss: 1.6955 - val_accuracy: 0.2532\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 1.4900 - accuracy: 0.3690 - val_loss: 1.4379 - val_accuracy: 0.3750\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 1.3275 - accuracy: 0.4363 - val_loss: 1.4862 - val_accuracy: 0.4263\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 1.2398 - accuracy: 0.4869 - val_loss: 1.2850 - val_accuracy: 0.4776\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 1.1508 - accuracy: 0.5131 - val_loss: 1.1535 - val_accuracy: 0.5192\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 1.1242 - accuracy: 0.5432 - val_loss: 1.3703 - val_accuracy: 0.4295\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 1.0376 - accuracy: 0.5867 - val_loss: 1.1773 - val_accuracy: 0.4904\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 1.0350 - accuracy: 0.5740 - val_loss: 1.2339 - val_accuracy: 0.5096\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.9361 - accuracy: 0.6334 - val_loss: 1.0317 - val_accuracy: 0.5833\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.8589 - accuracy: 0.6635 - val_loss: 1.0172 - val_accuracy: 0.6058\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.7908 - accuracy: 0.7039 - val_loss: 0.9870 - val_accuracy: 0.5994\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.7412 - accuracy: 0.7348 - val_loss: 1.0141 - val_accuracy: 0.6122\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.6773 - accuracy: 0.7482 - val_loss: 1.0949 - val_accuracy: 0.6058\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.6911 - accuracy: 0.7340 - val_loss: 0.9983 - val_accuracy: 0.6058\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.6419 - accuracy: 0.7664 - val_loss: 0.9860 - val_accuracy: 0.6474\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.5927 - accuracy: 0.7894 - val_loss: 1.1490 - val_accuracy: 0.6154\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.5986 - accuracy: 0.7736 - val_loss: 0.9973 - val_accuracy: 0.6314\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.5293 - accuracy: 0.8029 - val_loss: 1.0408 - val_accuracy: 0.6378\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.4974 - accuracy: 0.8171 - val_loss: 1.1388 - val_accuracy: 0.6186\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.4574 - accuracy: 0.8266 - val_loss: 1.1249 - val_accuracy: 0.6314\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.4319 - accuracy: 0.8337 - val_loss: 1.0127 - val_accuracy: 0.6571\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.4052 - accuracy: 0.8551 - val_loss: 1.2154 - val_accuracy: 0.6186\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.3719 - accuracy: 0.8614 - val_loss: 1.2702 - val_accuracy: 0.6218\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.3403 - accuracy: 0.8812 - val_loss: 1.0888 - val_accuracy: 0.6410\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.3047 - accuracy: 0.8899 - val_loss: 1.2122 - val_accuracy: 0.6378\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.2913 - accuracy: 0.8907 - val_loss: 1.3044 - val_accuracy: 0.6090\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.2945 - accuracy: 0.8868 - val_loss: 1.2198 - val_accuracy: 0.6346\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.3002 - accuracy: 0.8923 - val_loss: 1.3792 - val_accuracy: 0.5897\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.2904 - accuracy: 0.8939 - val_loss: 1.1534 - val_accuracy: 0.6314\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.2422 - accuracy: 0.9161 - val_loss: 1.4607 - val_accuracy: 0.6186\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.2601 - accuracy: 0.8987 - val_loss: 1.3961 - val_accuracy: 0.6218\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.2314 - accuracy: 0.9240 - val_loss: 1.4524 - val_accuracy: 0.6090\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.1847 - accuracy: 0.9335 - val_loss: 1.4932 - val_accuracy: 0.6186\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.2029 - accuracy: 0.9208 - val_loss: 1.4913 - val_accuracy: 0.5833\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.2129 - accuracy: 0.9256 - val_loss: 1.3857 - val_accuracy: 0.6410\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.1850 - accuracy: 0.9303 - val_loss: 1.4725 - val_accuracy: 0.6442\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.1387 - accuracy: 0.9509 - val_loss: 1.7949 - val_accuracy: 0.6218\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.1176 - accuracy: 0.9644 - val_loss: 1.6635 - val_accuracy: 0.6346\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.1245 - accuracy: 0.9557 - val_loss: 1.8227 - val_accuracy: 0.6026\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0819 - accuracy: 0.9755 - val_loss: 1.8464 - val_accuracy: 0.6122\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.1648 - accuracy: 0.9398 - val_loss: 1.7926 - val_accuracy: 0.6154\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.1965 - accuracy: 0.9343 - val_loss: 1.8261 - val_accuracy: 0.6058\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.1248 - accuracy: 0.9485 - val_loss: 2.0564 - val_accuracy: 0.5897\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.1090 - accuracy: 0.9628 - val_loss: 2.3325 - val_accuracy: 0.5865\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.1266 - accuracy: 0.9541 - val_loss: 2.1080 - val_accuracy: 0.5962\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.1158 - accuracy: 0.9565 - val_loss: 2.0985 - val_accuracy: 0.6186\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 6s 146ms/step - loss: 0.0911 - accuracy: 0.9675 - val_loss: 2.2194 - val_accuracy: 0.6186\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.0643 - accuracy: 0.9762 - val_loss: 2.3172 - val_accuracy: 0.5929\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.0697 - accuracy: 0.9723 - val_loss: 2.8338 - val_accuracy: 0.5673\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.1064 - accuracy: 0.9604 - val_loss: 2.0969 - val_accuracy: 0.6058\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.0450 - accuracy: 0.9873 - val_loss: 2.0916 - val_accuracy: 0.6378\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0223 - accuracy: 0.9960 - val_loss: 2.0817 - val_accuracy: 0.6314\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.0175 - accuracy: 0.9968 - val_loss: 2.1819 - val_accuracy: 0.6442\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0158 - accuracy: 0.9976 - val_loss: 2.2640 - val_accuracy: 0.6346\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.3561 - val_accuracy: 0.6442\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.4542 - val_accuracy: 0.6282\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5025 - val_accuracy: 0.6346\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5856 - val_accuracy: 0.6250\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6214 - val_accuracy: 0.6282\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6193 - val_accuracy: 0.6314\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6767 - val_accuracy: 0.6314\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7442 - val_accuracy: 0.6218\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7317 - val_accuracy: 0.6346\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7830 - val_accuracy: 0.6282\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.7996 - val_accuracy: 0.6250\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 9.7989e-04 - accuracy: 1.0000 - val_loss: 2.7908 - val_accuracy: 0.6314\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 9.1965e-04 - accuracy: 1.0000 - val_loss: 2.8330 - val_accuracy: 0.6314\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 8.3325e-04 - accuracy: 1.0000 - val_loss: 2.8620 - val_accuracy: 0.6346\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 7.9567e-04 - accuracy: 1.0000 - val_loss: 2.8909 - val_accuracy: 0.6282\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 7.4468e-04 - accuracy: 1.0000 - val_loss: 2.9227 - val_accuracy: 0.6282\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 7.0613e-04 - accuracy: 1.0000 - val_loss: 2.9260 - val_accuracy: 0.6282\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 6.7373e-04 - accuracy: 1.0000 - val_loss: 2.9420 - val_accuracy: 0.6314\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 6.3085e-04 - accuracy: 1.0000 - val_loss: 2.9652 - val_accuracy: 0.6282\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 5.9259e-04 - accuracy: 1.0000 - val_loss: 3.0391 - val_accuracy: 0.6314\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 5.8152e-04 - accuracy: 1.0000 - val_loss: 2.9747 - val_accuracy: 0.6346\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 5.4159e-04 - accuracy: 1.0000 - val_loss: 3.0196 - val_accuracy: 0.6346\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 5.2859e-04 - accuracy: 1.0000 - val_loss: 3.0551 - val_accuracy: 0.6250\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 4.9139e-04 - accuracy: 1.0000 - val_loss: 3.0734 - val_accuracy: 0.6218\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 4.7167e-04 - accuracy: 1.0000 - val_loss: 3.1367 - val_accuracy: 0.6218\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 4.5474e-04 - accuracy: 1.0000 - val_loss: 3.1157 - val_accuracy: 0.6250\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 4.2570e-04 - accuracy: 1.0000 - val_loss: 3.1183 - val_accuracy: 0.6282\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 4.0484e-04 - accuracy: 1.0000 - val_loss: 3.1352 - val_accuracy: 0.6314\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 3.9092e-04 - accuracy: 1.0000 - val_loss: 3.1585 - val_accuracy: 0.6282\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 3.7445e-04 - accuracy: 1.0000 - val_loss: 3.1999 - val_accuracy: 0.6218\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 3.5747e-04 - accuracy: 1.0000 - val_loss: 3.1622 - val_accuracy: 0.6378\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 3.5277e-04 - accuracy: 1.0000 - val_loss: 3.1871 - val_accuracy: 0.6282\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 3.2881e-04 - accuracy: 1.0000 - val_loss: 3.2384 - val_accuracy: 0.6250\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 3.1920e-04 - accuracy: 1.0000 - val_loss: 3.2482 - val_accuracy: 0.6218\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 3.0609e-04 - accuracy: 1.0000 - val_loss: 3.2685 - val_accuracy: 0.6218\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 6s 148ms/step - loss: 2.9279e-04 - accuracy: 1.0000 - val_loss: 3.2479 - val_accuracy: 0.6314\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 2.8482e-04 - accuracy: 1.0000 - val_loss: 3.2975 - val_accuracy: 0.6250\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 7s 165ms/step - loss: 2.7105e-04 - accuracy: 1.0000 - val_loss: 3.2944 - val_accuracy: 0.6314\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 10s 245ms/step - loss: 2.6306e-04 - accuracy: 1.0000 - val_loss: 3.3128 - val_accuracy: 0.6250\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 9s 215ms/step - loss: 2.5032e-04 - accuracy: 1.0000 - val_loss: 3.3241 - val_accuracy: 0.6282\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 7s 185ms/step - loss: 2.4452e-04 - accuracy: 1.0000 - val_loss: 3.3380 - val_accuracy: 0.6250\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 2.3524e-04 - accuracy: 1.0000 - val_loss: 3.3427 - val_accuracy: 0.6314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "DMmriwt4-tjs",
        "outputId": "07fc0be2-cb5b-4581-9381-6e60fdd11cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/40 [=========>....................] - ETA: 8s - loss: 1.9596 - accuracy: 0.1384"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-434e88366ba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q6fTlVDcKhbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gQ3jr3SPKmk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WRwTlAbXK_tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6H7_2agULF6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "GhnBy0_4KiGi",
        "outputId": "aa42c4a5-af5f-46d7-8f2e-133f77da2411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f30562f08eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mefficientnet_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficientnet_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m efficientnet_model.compile(loss= \"categorical_crossentropy\",\n\u001b[1;32m      3\u001b[0m                       \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       metrics=[\"accuracy\"])\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Fitting the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-7bcc325e173f>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_url, num_classes)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"feature_extracter_layer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                           input_shape=IMAGE_SHAPE+(3,))\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0;31m#create a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   model = tf.keras.Sequential([\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'tuple'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fp6m1-qpK-G3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}